{"cells":[{"cell_type":"markdown","source":["# HW 3 - Synonym Detection In Spark - Shishir Agarwal (Please note Q#6 takes about 40 minutes to complete on my cluster)\n__`MIDS w261: Machine Learning at Scale | UC Berkeley School of Information | Fall 2018`__\n\nIn the last homework assignment you performed Naive Bayes to classify documents as 'ham' or 'spam.' In doing so, we relied on the implicit assumption that the list of words in a document can tell us something about the nature of that document's content. We'll rely on a similar intuition this week: the idea that, if we analyze a large enough corpus of text, the list of words that appear in small window before or after a vocabulary term can tell us something about that term's meaning.\n\nThis will be your first assignment working in Spark. You'll perform Synonym Detection by repurposing an algorithm commonly used in Natural Language Processing to perform document similarity analysis. In doing so you'll also become familiar with important datatypes for efficiently processing sparse vectors and a number of set similarity metrics (e.g. Cosine, Jaccard, Dice). By the end of this homework you should be able to:  \n* ... __define__ the terms `one-hot encoding`, `co-occurrance matrix`, `stripe`, `inverted index`, `postings`, and `basis vocabulary` in the context of both synonym detection and document similarity analysis.\n* ... __explain__ the reasoning behind using a word stripe to compare word meanings.\n* ... __identify__ what makes set-similarity calculations computationally challenging.\n* ... __implement__ stateless algorithms in Spark to build stripes, inverted index and compute similarity metrics.\n* ... __apply__ appropriate metrics to assess the performance of your synonym detection algorithm. \n\n\n__`NOTE`__: your reading assignment for weeks 5 and 6 were fairly heavy and you may have glossed over the papers on dimension independent similarity metrics by [Zadeh et al](http://stanford.edu/~rezab/papers/disco.pdf) and pairwise document similarity by [Elsayed et al](https://terpconnect.umd.edu/~oard/pdf/acl08elsayed2.pdf). If you haven't already, this would be a good time to review those readings -- they are directly relevant to this assignment.\n\n__Please refer to the `README` for homework submission instructions and additional resources.__"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d19068d9-8d33-4854-8f94-00ad659f13b4"}}},{"cell_type":"markdown","source":["# Notebook Set-Up\nBefore starting your homework run the following cells to confirm your setup."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd152905-23b0-4e63-82f4-d947a58cc554"}}},{"cell_type":"code","source":["import re\nimport ast\nimport time\nimport itertools\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"39778a74-de75-4047-a0fa-6a288253c024"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Run the next cell to create your directory in dbfs\nYou do not need to understand this scala snippet. It simply dynamically fetches your user directory name so that any files you write can be saved in your own directory."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2f0ebc70-164e-415d-b996-359c56e54192"}}},{"cell_type":"code","source":["# RUN THIS CELL AS IS\n# This code snippet reads the user directory name, and stores is in a python variable.\n# Next, it creates a folder inside your home folder, which you will use for files which you save inside this notebook.\nusername = dbutils.notebook.entry_point.getDbutils().notebook().getContext().tags().apply('user')\nuserhome = 'dbfs:/user/' + username\nprint(userhome)\nhw3_path = userhome + \"/hw3/\" \nhw3_path_open = '/dbfs' + hw3_path.split(':')[-1] # for use with python open()\ndbutils.fs.mkdirs(hw3_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ed29cbb8-68a0-44de-984e-54f67df2186d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">dbfs:/user/shishir.agarwal@ischool.berkeley.edu\nOut[20]: True</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">dbfs:/user/shishir.agarwal@ischool.berkeley.edu\nOut[20]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# RUN THIS CELL AS IS - A test to make sure your directory is working as expected.\n# You should see a result like:\n# dbfs:/user/youremail@ischool.berkeley.edu/hw3/sample_docs.txt\ndbutils.fs.put(hw3_path+'test.txt',\"hello world\",True)\ndisplay(dbutils.fs.ls(hw3_path))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e0d98a9-07ea-412f-860c-78ac8de610d6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Wrote 11 bytes.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Wrote 11 bytes.\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/user/shishir.agarwal@ischool.berkeley.edu/hw3/basis.txt","basis.txt",11948],["dbfs:/user/shishir.agarwal@ischool.berkeley.edu/hw3/sample_docs.txt","sample_docs.txt",144],["dbfs:/user/shishir.agarwal@ischool.berkeley.edu/hw3/stripes/","stripes/",0],["dbfs:/user/shishir.agarwal@ischool.berkeley.edu/hw3/systems_test.txt","systems_test.txt",493],["dbfs:/user/shishir.agarwal@ischool.berkeley.edu/hw3/test.txt","test.txt",11],["dbfs:/user/shishir.agarwal@ischool.berkeley.edu/hw3/vocabulary.txt","vocabulary.txt",113523]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/user/shishir.agarwal@ischool.berkeley.edu/hw3/basis.txt</td><td>basis.txt</td><td>11948</td></tr><tr><td>dbfs:/user/shishir.agarwal@ischool.berkeley.edu/hw3/sample_docs.txt</td><td>sample_docs.txt</td><td>144</td></tr><tr><td>dbfs:/user/shishir.agarwal@ischool.berkeley.edu/hw3/stripes/</td><td>stripes/</td><td>0</td></tr><tr><td>dbfs:/user/shishir.agarwal@ischool.berkeley.edu/hw3/systems_test.txt</td><td>systems_test.txt</td><td>493</td></tr><tr><td>dbfs:/user/shishir.agarwal@ischool.berkeley.edu/hw3/test.txt</td><td>test.txt</td><td>11</td></tr><tr><td>dbfs:/user/shishir.agarwal@ischool.berkeley.edu/hw3/vocabulary.txt</td><td>vocabulary.txt</td><td>113523</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# RUN THIS CELL AS IS. You should see multiple google-eng-all-5gram-* files in the results. If you do not see these, please let an Instructor or TA know.\ndisplay(dbutils.fs.ls('/mnt/mids-w261/HW3/'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f72fae3c-c592-40cc-8377-7a5da49f426b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-0-filtered.txt","googlebooks-eng-all-5gram-20090715-0-filtered.txt",11444614],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-1-filtered.txt","googlebooks-eng-all-5gram-20090715-1-filtered.txt",0],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-10-filtered.txt","googlebooks-eng-all-5gram-20090715-10-filtered.txt",11447003],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-100-filtered.txt","googlebooks-eng-all-5gram-20090715-100-filtered.txt",11484723],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-101-filtered.txt","googlebooks-eng-all-5gram-20090715-101-filtered.txt",11473190],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-102-filtered.txt","googlebooks-eng-all-5gram-20090715-102-filtered.txt",11411047],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-103-filtered.txt","googlebooks-eng-all-5gram-20090715-103-filtered.txt",11479296],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-104-filtered.txt","googlebooks-eng-all-5gram-20090715-104-filtered.txt",11426686],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-105-filtered.txt","googlebooks-eng-all-5gram-20090715-105-filtered.txt",11482267],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-106-filtered.txt","googlebooks-eng-all-5gram-20090715-106-filtered.txt",11466886],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-107-filtered.txt","googlebooks-eng-all-5gram-20090715-107-filtered.txt",11485960],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-108-filtered.txt","googlebooks-eng-all-5gram-20090715-108-filtered.txt",11463278],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-109-filtered.txt","googlebooks-eng-all-5gram-20090715-109-filtered.txt",11446599],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-11-filtered.txt","googlebooks-eng-all-5gram-20090715-11-filtered.txt",11495017],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-110-filtered.txt","googlebooks-eng-all-5gram-20090715-110-filtered.txt",11450101],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-111-filtered.txt","googlebooks-eng-all-5gram-20090715-111-filtered.txt",11456942],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-112-filtered.txt","googlebooks-eng-all-5gram-20090715-112-filtered.txt",11463851],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-113-filtered.txt","googlebooks-eng-all-5gram-20090715-113-filtered.txt",11457743],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-114-filtered.txt","googlebooks-eng-all-5gram-20090715-114-filtered.txt",11480874],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-115-filtered.txt","googlebooks-eng-all-5gram-20090715-115-filtered.txt",11504547],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-116-filtered.txt","googlebooks-eng-all-5gram-20090715-116-filtered.txt",11431759],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-117-filtered.txt","googlebooks-eng-all-5gram-20090715-117-filtered.txt",11451033],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-118-filtered.txt","googlebooks-eng-all-5gram-20090715-118-filtered.txt",11499348],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-119-filtered.txt","googlebooks-eng-all-5gram-20090715-119-filtered.txt",11461816],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-12-filtered.txt","googlebooks-eng-all-5gram-20090715-12-filtered.txt",11443168],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-120-filtered.txt","googlebooks-eng-all-5gram-20090715-120-filtered.txt",11478681],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-121-filtered.txt","googlebooks-eng-all-5gram-20090715-121-filtered.txt",11452388],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-122-filtered.txt","googlebooks-eng-all-5gram-20090715-122-filtered.txt",11461706],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-123-filtered.txt","googlebooks-eng-all-5gram-20090715-123-filtered.txt",11489973],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-124-filtered.txt","googlebooks-eng-all-5gram-20090715-124-filtered.txt",11482331],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-125-filtered.txt","googlebooks-eng-all-5gram-20090715-125-filtered.txt",11462905],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-126-filtered.txt","googlebooks-eng-all-5gram-20090715-126-filtered.txt",11467767],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-127-filtered.txt","googlebooks-eng-all-5gram-20090715-127-filtered.txt",11459598],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-128-filtered.txt","googlebooks-eng-all-5gram-20090715-128-filtered.txt",11443935],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-129-filtered.txt","googlebooks-eng-all-5gram-20090715-129-filtered.txt",11433432],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-13-filtered.txt","googlebooks-eng-all-5gram-20090715-13-filtered.txt",11485635],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-130-filtered.txt","googlebooks-eng-all-5gram-20090715-130-filtered.txt",11457212],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-131-filtered.txt","googlebooks-eng-all-5gram-20090715-131-filtered.txt",11472377],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-132-filtered.txt","googlebooks-eng-all-5gram-20090715-132-filtered.txt",11493120],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-133-filtered.txt","googlebooks-eng-all-5gram-20090715-133-filtered.txt",11441679],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-134-filtered.txt","googlebooks-eng-all-5gram-20090715-134-filtered.txt",11470516],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-135-filtered.txt","googlebooks-eng-all-5gram-20090715-135-filtered.txt",11456972],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-136-filtered.txt","googlebooks-eng-all-5gram-20090715-136-filtered.txt",11492095],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-137-filtered.txt","googlebooks-eng-all-5gram-20090715-137-filtered.txt",11446669],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-138-filtered.txt","googlebooks-eng-all-5gram-20090715-138-filtered.txt",11466514],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-139-filtered.txt","googlebooks-eng-all-5gram-20090715-139-filtered.txt",11459726],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-14-filtered.txt","googlebooks-eng-all-5gram-20090715-14-filtered.txt",11442376],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-140-filtered.txt","googlebooks-eng-all-5gram-20090715-140-filtered.txt",11460720],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-141-filtered.txt","googlebooks-eng-all-5gram-20090715-141-filtered.txt",11483474],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-142-filtered.txt","googlebooks-eng-all-5gram-20090715-142-filtered.txt",11447339],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-143-filtered.txt","googlebooks-eng-all-5gram-20090715-143-filtered.txt",11526964],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-144-filtered.txt","googlebooks-eng-all-5gram-20090715-144-filtered.txt",11435580],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-145-filtered.txt","googlebooks-eng-all-5gram-20090715-145-filtered.txt",11471874],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-146-filtered.txt","googlebooks-eng-all-5gram-20090715-146-filtered.txt",11432836],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-147-filtered.txt","googlebooks-eng-all-5gram-20090715-147-filtered.txt",11459158],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-148-filtered.txt","googlebooks-eng-all-5gram-20090715-148-filtered.txt",11454244],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-149-filtered.txt","googlebooks-eng-all-5gram-20090715-149-filtered.txt",11451707],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-15-filtered.txt","googlebooks-eng-all-5gram-20090715-15-filtered.txt",11452631],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-150-filtered.txt","googlebooks-eng-all-5gram-20090715-150-filtered.txt",11473902],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-151-filtered.txt","googlebooks-eng-all-5gram-20090715-151-filtered.txt",11469708],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-152-filtered.txt","googlebooks-eng-all-5gram-20090715-152-filtered.txt",11455532],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-153-filtered.txt","googlebooks-eng-all-5gram-20090715-153-filtered.txt",11501176],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-154-filtered.txt","googlebooks-eng-all-5gram-20090715-154-filtered.txt",11515944],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-155-filtered.txt","googlebooks-eng-all-5gram-20090715-155-filtered.txt",11464571],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-156-filtered.txt","googlebooks-eng-all-5gram-20090715-156-filtered.txt",11470657],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-157-filtered.txt","googlebooks-eng-all-5gram-20090715-157-filtered.txt",11445685],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-158-filtered.txt","googlebooks-eng-all-5gram-20090715-158-filtered.txt",11472240],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-159-filtered.txt","googlebooks-eng-all-5gram-20090715-159-filtered.txt",11476035],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-16-filtered.txt","googlebooks-eng-all-5gram-20090715-16-filtered.txt",11525458],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-160-filtered.txt","googlebooks-eng-all-5gram-20090715-160-filtered.txt",11452574],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-161-filtered.txt","googlebooks-eng-all-5gram-20090715-161-filtered.txt",11464062],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-162-filtered.txt","googlebooks-eng-all-5gram-20090715-162-filtered.txt",11486898],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-163-filtered.txt","googlebooks-eng-all-5gram-20090715-163-filtered.txt",11477376],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-164-filtered.txt","googlebooks-eng-all-5gram-20090715-164-filtered.txt",11505357],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-165-filtered.txt","googlebooks-eng-all-5gram-20090715-165-filtered.txt",11462181],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-166-filtered.txt","googlebooks-eng-all-5gram-20090715-166-filtered.txt",11466783],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-167-filtered.txt","googlebooks-eng-all-5gram-20090715-167-filtered.txt",11462354],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-168-filtered.txt","googlebooks-eng-all-5gram-20090715-168-filtered.txt",11506473],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-169-filtered.txt","googlebooks-eng-all-5gram-20090715-169-filtered.txt",11472965],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-17-filtered.txt","googlebooks-eng-all-5gram-20090715-17-filtered.txt",11509921],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-170-filtered.txt","googlebooks-eng-all-5gram-20090715-170-filtered.txt",11469219],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-171-filtered.txt","googlebooks-eng-all-5gram-20090715-171-filtered.txt",11467382],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-172-filtered.txt","googlebooks-eng-all-5gram-20090715-172-filtered.txt",11415310],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-173-filtered.txt","googlebooks-eng-all-5gram-20090715-173-filtered.txt",11457481],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-174-filtered.txt","googlebooks-eng-all-5gram-20090715-174-filtered.txt",11496657],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-175-filtered.txt","googlebooks-eng-all-5gram-20090715-175-filtered.txt",11470283],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-176-filtered.txt","googlebooks-eng-all-5gram-20090715-176-filtered.txt",11441689],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-177-filtered.txt","googlebooks-eng-all-5gram-20090715-177-filtered.txt",11484462],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-178-filtered.txt","googlebooks-eng-all-5gram-20090715-178-filtered.txt",11494587],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-179-filtered.txt","googlebooks-eng-all-5gram-20090715-179-filtered.txt",11430020],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-18-filtered.txt","googlebooks-eng-all-5gram-20090715-18-filtered.txt",11492843],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-180-filtered.txt","googlebooks-eng-all-5gram-20090715-180-filtered.txt",11464793],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-181-filtered.txt","googlebooks-eng-all-5gram-20090715-181-filtered.txt",11478471],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-182-filtered.txt","googlebooks-eng-all-5gram-20090715-182-filtered.txt",11505360],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-183-filtered.txt","googlebooks-eng-all-5gram-20090715-183-filtered.txt",11486325],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-184-filtered.txt","googlebooks-eng-all-5gram-20090715-184-filtered.txt",11452312],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-185-filtered.txt","googlebooks-eng-all-5gram-20090715-185-filtered.txt",11457259],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-186-filtered.txt","googlebooks-eng-all-5gram-20090715-186-filtered.txt",11471607],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-187-filtered.txt","googlebooks-eng-all-5gram-20090715-187-filtered.txt",11444970],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-188-filtered.txt","googlebooks-eng-all-5gram-20090715-188-filtered.txt",11456589],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-189-filtered.txt","googlebooks-eng-all-5gram-20090715-189-filtered.txt",11445694],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-19-filtered.txt","googlebooks-eng-all-5gram-20090715-19-filtered.txt",11446280],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-2-filtered.txt","googlebooks-eng-all-5gram-20090715-2-filtered.txt",11469040],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-20-filtered.txt","googlebooks-eng-all-5gram-20090715-20-filtered.txt",11483940],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-21-filtered.txt","googlebooks-eng-all-5gram-20090715-21-filtered.txt",11419380],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-22-filtered.txt","googlebooks-eng-all-5gram-20090715-22-filtered.txt",11504055],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-23-filtered.txt","googlebooks-eng-all-5gram-20090715-23-filtered.txt",11444833],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-24-filtered.txt","googlebooks-eng-all-5gram-20090715-24-filtered.txt",11470920],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-25-filtered.txt","googlebooks-eng-all-5gram-20090715-25-filtered.txt",11447510],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-26-filtered.txt","googlebooks-eng-all-5gram-20090715-26-filtered.txt",11451162],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-27-filtered.txt","googlebooks-eng-all-5gram-20090715-27-filtered.txt",11432861],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-28-filtered.txt","googlebooks-eng-all-5gram-20090715-28-filtered.txt",11473738],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-29-filtered.txt","googlebooks-eng-all-5gram-20090715-29-filtered.txt",11466285],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-3-filtered.txt","googlebooks-eng-all-5gram-20090715-3-filtered.txt",11473472],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-30-filtered.txt","googlebooks-eng-all-5gram-20090715-30-filtered.txt",11451427],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-31-filtered.txt","googlebooks-eng-all-5gram-20090715-31-filtered.txt",11445890],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-32-filtered.txt","googlebooks-eng-all-5gram-20090715-32-filtered.txt",11451034],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-33-filtered.txt","googlebooks-eng-all-5gram-20090715-33-filtered.txt",11448837],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-34-filtered.txt","googlebooks-eng-all-5gram-20090715-34-filtered.txt",11477127],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-35-filtered.txt","googlebooks-eng-all-5gram-20090715-35-filtered.txt",11482525],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-36-filtered.txt","googlebooks-eng-all-5gram-20090715-36-filtered.txt",11485001],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-37-filtered.txt","googlebooks-eng-all-5gram-20090715-37-filtered.txt",11462556],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-38-filtered.txt","googlebooks-eng-all-5gram-20090715-38-filtered.txt",11471356],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-39-filtered.txt","googlebooks-eng-all-5gram-20090715-39-filtered.txt",11463027],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-4-filtered.txt","googlebooks-eng-all-5gram-20090715-4-filtered.txt",11474462],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-40-filtered.txt","googlebooks-eng-all-5gram-20090715-40-filtered.txt",11479067],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-41-filtered.txt","googlebooks-eng-all-5gram-20090715-41-filtered.txt",11492731],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-42-filtered.txt","googlebooks-eng-all-5gram-20090715-42-filtered.txt",11444143],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-43-filtered.txt","googlebooks-eng-all-5gram-20090715-43-filtered.txt",11457891],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-44-filtered.txt","googlebooks-eng-all-5gram-20090715-44-filtered.txt",11477565],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-45-filtered.txt","googlebooks-eng-all-5gram-20090715-45-filtered.txt",11491534],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-46-filtered.txt","googlebooks-eng-all-5gram-20090715-46-filtered.txt",0],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-47-filtered.txt","googlebooks-eng-all-5gram-20090715-47-filtered.txt",11437493],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-48-filtered.txt","googlebooks-eng-all-5gram-20090715-48-filtered.txt",11486342],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-49-filtered.txt","googlebooks-eng-all-5gram-20090715-49-filtered.txt",11506157],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-5-filtered.txt","googlebooks-eng-all-5gram-20090715-5-filtered.txt",11486767],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-50-filtered.txt","googlebooks-eng-all-5gram-20090715-50-filtered.txt",11448291],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-51-filtered.txt","googlebooks-eng-all-5gram-20090715-51-filtered.txt",11466332],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-52-filtered.txt","googlebooks-eng-all-5gram-20090715-52-filtered.txt",11454748],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-53-filtered.txt","googlebooks-eng-all-5gram-20090715-53-filtered.txt",11473706],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-54-filtered.txt","googlebooks-eng-all-5gram-20090715-54-filtered.txt",11449750],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-55-filtered.txt","googlebooks-eng-all-5gram-20090715-55-filtered.txt",11440722],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-56-filtered.txt","googlebooks-eng-all-5gram-20090715-56-filtered.txt",11443428],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-57-filtered.txt","googlebooks-eng-all-5gram-20090715-57-filtered.txt",11523191],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-58-filtered.txt","googlebooks-eng-all-5gram-20090715-58-filtered.txt",11464003],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-59-filtered.txt","googlebooks-eng-all-5gram-20090715-59-filtered.txt",11450319],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-6-filtered.txt","googlebooks-eng-all-5gram-20090715-6-filtered.txt",11465378],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-60-filtered.txt","googlebooks-eng-all-5gram-20090715-60-filtered.txt",11477145],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-61-filtered.txt","googlebooks-eng-all-5gram-20090715-61-filtered.txt",11484900],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-62-filtered.txt","googlebooks-eng-all-5gram-20090715-62-filtered.txt",11461230],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-63-filtered.txt","googlebooks-eng-all-5gram-20090715-63-filtered.txt",11479759],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-64-filtered.txt","googlebooks-eng-all-5gram-20090715-64-filtered.txt",11445477],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-65-filtered.txt","googlebooks-eng-all-5gram-20090715-65-filtered.txt",11519941],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-66-filtered.txt","googlebooks-eng-all-5gram-20090715-66-filtered.txt",11455135],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-67-filtered.txt","googlebooks-eng-all-5gram-20090715-67-filtered.txt",11463820],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-68-filtered.txt","googlebooks-eng-all-5gram-20090715-68-filtered.txt",11502857],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-69-filtered.txt","googlebooks-eng-all-5gram-20090715-69-filtered.txt",11510895],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-7-filtered.txt","googlebooks-eng-all-5gram-20090715-7-filtered.txt",11459099],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-70-filtered.txt","googlebooks-eng-all-5gram-20090715-70-filtered.txt",11431260],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-71-filtered.txt","googlebooks-eng-all-5gram-20090715-71-filtered.txt",11465722],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-72-filtered.txt","googlebooks-eng-all-5gram-20090715-72-filtered.txt",11495024],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-73-filtered.txt","googlebooks-eng-all-5gram-20090715-73-filtered.txt",11474806],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-74-filtered.txt","googlebooks-eng-all-5gram-20090715-74-filtered.txt",11491417],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-75-filtered.txt","googlebooks-eng-all-5gram-20090715-75-filtered.txt",11484503],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-76-filtered.txt","googlebooks-eng-all-5gram-20090715-76-filtered.txt",11458149],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-77-filtered.txt","googlebooks-eng-all-5gram-20090715-77-filtered.txt",11473636],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-78-filtered.txt","googlebooks-eng-all-5gram-20090715-78-filtered.txt",11479521],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-79-filtered.txt","googlebooks-eng-all-5gram-20090715-79-filtered.txt",11430938],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-8-filtered.txt","googlebooks-eng-all-5gram-20090715-8-filtered.txt",11455035],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-80-filtered.txt","googlebooks-eng-all-5gram-20090715-80-filtered.txt",11464432],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-81-filtered.txt","googlebooks-eng-all-5gram-20090715-81-filtered.txt",11473302],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-82-filtered.txt","googlebooks-eng-all-5gram-20090715-82-filtered.txt",11457728],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-83-filtered.txt","googlebooks-eng-all-5gram-20090715-83-filtered.txt",11510120],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-84-filtered.txt","googlebooks-eng-all-5gram-20090715-84-filtered.txt",11459989],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-85-filtered.txt","googlebooks-eng-all-5gram-20090715-85-filtered.txt",11487885],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-86-filtered.txt","googlebooks-eng-all-5gram-20090715-86-filtered.txt",11492162],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-87-filtered.txt","googlebooks-eng-all-5gram-20090715-87-filtered.txt",11487948],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-88-filtered.txt","googlebooks-eng-all-5gram-20090715-88-filtered.txt",11452445],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-89-filtered.txt","googlebooks-eng-all-5gram-20090715-89-filtered.txt",11507487],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-9-filtered.txt","googlebooks-eng-all-5gram-20090715-9-filtered.txt",11450336],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-90-filtered.txt","googlebooks-eng-all-5gram-20090715-90-filtered.txt",11525239],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-91-filtered.txt","googlebooks-eng-all-5gram-20090715-91-filtered.txt",11468711],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-92-filtered.txt","googlebooks-eng-all-5gram-20090715-92-filtered.txt",11458184],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-93-filtered.txt","googlebooks-eng-all-5gram-20090715-93-filtered.txt",11474240],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-94-filtered.txt","googlebooks-eng-all-5gram-20090715-94-filtered.txt",11471885],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-95-filtered.txt","googlebooks-eng-all-5gram-20090715-95-filtered.txt",11488721],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-96-filtered.txt","googlebooks-eng-all-5gram-20090715-96-filtered.txt",11483342],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-97-filtered.txt","googlebooks-eng-all-5gram-20090715-97-filtered.txt",11451041],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-98-filtered.txt","googlebooks-eng-all-5gram-20090715-98-filtered.txt",11464391],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-99-filtered.txt","googlebooks-eng-all-5gram-20090715-99-filtered.txt",11479936]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-0-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-0-filtered.txt</td><td>11444614</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-1-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-1-filtered.txt</td><td>0</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-10-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-10-filtered.txt</td><td>11447003</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-100-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-100-filtered.txt</td><td>11484723</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-101-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-101-filtered.txt</td><td>11473190</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-102-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-102-filtered.txt</td><td>11411047</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-103-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-103-filtered.txt</td><td>11479296</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-104-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-104-filtered.txt</td><td>11426686</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-105-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-105-filtered.txt</td><td>11482267</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-106-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-106-filtered.txt</td><td>11466886</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-107-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-107-filtered.txt</td><td>11485960</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-108-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-108-filtered.txt</td><td>11463278</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-109-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-109-filtered.txt</td><td>11446599</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-11-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-11-filtered.txt</td><td>11495017</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-110-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-110-filtered.txt</td><td>11450101</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-111-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-111-filtered.txt</td><td>11456942</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-112-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-112-filtered.txt</td><td>11463851</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-113-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-113-filtered.txt</td><td>11457743</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-114-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-114-filtered.txt</td><td>11480874</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-115-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-115-filtered.txt</td><td>11504547</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-116-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-116-filtered.txt</td><td>11431759</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-117-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-117-filtered.txt</td><td>11451033</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-118-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-118-filtered.txt</td><td>11499348</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-119-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-119-filtered.txt</td><td>11461816</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-12-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-12-filtered.txt</td><td>11443168</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-120-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-120-filtered.txt</td><td>11478681</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-121-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-121-filtered.txt</td><td>11452388</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-122-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-122-filtered.txt</td><td>11461706</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-123-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-123-filtered.txt</td><td>11489973</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-124-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-124-filtered.txt</td><td>11482331</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-125-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-125-filtered.txt</td><td>11462905</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-126-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-126-filtered.txt</td><td>11467767</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-127-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-127-filtered.txt</td><td>11459598</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-128-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-128-filtered.txt</td><td>11443935</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-129-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-129-filtered.txt</td><td>11433432</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-13-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-13-filtered.txt</td><td>11485635</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-130-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-130-filtered.txt</td><td>11457212</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-131-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-131-filtered.txt</td><td>11472377</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-132-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-132-filtered.txt</td><td>11493120</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-133-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-133-filtered.txt</td><td>11441679</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-134-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-134-filtered.txt</td><td>11470516</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-135-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-135-filtered.txt</td><td>11456972</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-136-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-136-filtered.txt</td><td>11492095</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-137-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-137-filtered.txt</td><td>11446669</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-138-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-138-filtered.txt</td><td>11466514</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-139-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-139-filtered.txt</td><td>11459726</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-14-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-14-filtered.txt</td><td>11442376</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-140-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-140-filtered.txt</td><td>11460720</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-141-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-141-filtered.txt</td><td>11483474</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-142-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-142-filtered.txt</td><td>11447339</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-143-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-143-filtered.txt</td><td>11526964</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-144-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-144-filtered.txt</td><td>11435580</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-145-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-145-filtered.txt</td><td>11471874</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-146-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-146-filtered.txt</td><td>11432836</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-147-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-147-filtered.txt</td><td>11459158</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-148-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-148-filtered.txt</td><td>11454244</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-149-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-149-filtered.txt</td><td>11451707</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-15-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-15-filtered.txt</td><td>11452631</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-150-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-150-filtered.txt</td><td>11473902</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-151-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-151-filtered.txt</td><td>11469708</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-152-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-152-filtered.txt</td><td>11455532</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-153-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-153-filtered.txt</td><td>11501176</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-154-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-154-filtered.txt</td><td>11515944</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-155-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-155-filtered.txt</td><td>11464571</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-156-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-156-filtered.txt</td><td>11470657</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-157-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-157-filtered.txt</td><td>11445685</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-158-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-158-filtered.txt</td><td>11472240</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-159-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-159-filtered.txt</td><td>11476035</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-16-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-16-filtered.txt</td><td>11525458</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-160-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-160-filtered.txt</td><td>11452574</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-161-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-161-filtered.txt</td><td>11464062</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-162-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-162-filtered.txt</td><td>11486898</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-163-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-163-filtered.txt</td><td>11477376</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-164-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-164-filtered.txt</td><td>11505357</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-165-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-165-filtered.txt</td><td>11462181</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-166-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-166-filtered.txt</td><td>11466783</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-167-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-167-filtered.txt</td><td>11462354</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-168-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-168-filtered.txt</td><td>11506473</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-169-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-169-filtered.txt</td><td>11472965</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-17-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-17-filtered.txt</td><td>11509921</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-170-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-170-filtered.txt</td><td>11469219</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-171-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-171-filtered.txt</td><td>11467382</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-172-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-172-filtered.txt</td><td>11415310</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-173-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-173-filtered.txt</td><td>11457481</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-174-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-174-filtered.txt</td><td>11496657</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-175-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-175-filtered.txt</td><td>11470283</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-176-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-176-filtered.txt</td><td>11441689</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-177-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-177-filtered.txt</td><td>11484462</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-178-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-178-filtered.txt</td><td>11494587</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-179-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-179-filtered.txt</td><td>11430020</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-18-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-18-filtered.txt</td><td>11492843</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-180-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-180-filtered.txt</td><td>11464793</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-181-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-181-filtered.txt</td><td>11478471</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-182-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-182-filtered.txt</td><td>11505360</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-183-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-183-filtered.txt</td><td>11486325</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-184-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-184-filtered.txt</td><td>11452312</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-185-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-185-filtered.txt</td><td>11457259</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-186-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-186-filtered.txt</td><td>11471607</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-187-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-187-filtered.txt</td><td>11444970</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-188-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-188-filtered.txt</td><td>11456589</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-189-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-189-filtered.txt</td><td>11445694</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-19-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-19-filtered.txt</td><td>11446280</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-2-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-2-filtered.txt</td><td>11469040</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-20-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-20-filtered.txt</td><td>11483940</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-21-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-21-filtered.txt</td><td>11419380</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-22-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-22-filtered.txt</td><td>11504055</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-23-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-23-filtered.txt</td><td>11444833</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-24-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-24-filtered.txt</td><td>11470920</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-25-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-25-filtered.txt</td><td>11447510</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-26-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-26-filtered.txt</td><td>11451162</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-27-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-27-filtered.txt</td><td>11432861</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-28-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-28-filtered.txt</td><td>11473738</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-29-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-29-filtered.txt</td><td>11466285</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-3-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-3-filtered.txt</td><td>11473472</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-30-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-30-filtered.txt</td><td>11451427</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-31-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-31-filtered.txt</td><td>11445890</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-32-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-32-filtered.txt</td><td>11451034</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-33-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-33-filtered.txt</td><td>11448837</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-34-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-34-filtered.txt</td><td>11477127</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-35-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-35-filtered.txt</td><td>11482525</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-36-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-36-filtered.txt</td><td>11485001</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-37-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-37-filtered.txt</td><td>11462556</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-38-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-38-filtered.txt</td><td>11471356</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-39-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-39-filtered.txt</td><td>11463027</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-4-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-4-filtered.txt</td><td>11474462</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-40-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-40-filtered.txt</td><td>11479067</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-41-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-41-filtered.txt</td><td>11492731</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-42-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-42-filtered.txt</td><td>11444143</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-43-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-43-filtered.txt</td><td>11457891</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-44-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-44-filtered.txt</td><td>11477565</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-45-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-45-filtered.txt</td><td>11491534</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-46-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-46-filtered.txt</td><td>0</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-47-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-47-filtered.txt</td><td>11437493</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-48-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-48-filtered.txt</td><td>11486342</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-49-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-49-filtered.txt</td><td>11506157</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-5-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-5-filtered.txt</td><td>11486767</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-50-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-50-filtered.txt</td><td>11448291</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-51-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-51-filtered.txt</td><td>11466332</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-52-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-52-filtered.txt</td><td>11454748</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-53-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-53-filtered.txt</td><td>11473706</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-54-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-54-filtered.txt</td><td>11449750</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-55-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-55-filtered.txt</td><td>11440722</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-56-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-56-filtered.txt</td><td>11443428</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-57-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-57-filtered.txt</td><td>11523191</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-58-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-58-filtered.txt</td><td>11464003</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-59-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-59-filtered.txt</td><td>11450319</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-6-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-6-filtered.txt</td><td>11465378</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-60-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-60-filtered.txt</td><td>11477145</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-61-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-61-filtered.txt</td><td>11484900</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-62-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-62-filtered.txt</td><td>11461230</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-63-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-63-filtered.txt</td><td>11479759</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-64-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-64-filtered.txt</td><td>11445477</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-65-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-65-filtered.txt</td><td>11519941</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-66-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-66-filtered.txt</td><td>11455135</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-67-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-67-filtered.txt</td><td>11463820</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-68-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-68-filtered.txt</td><td>11502857</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-69-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-69-filtered.txt</td><td>11510895</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-7-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-7-filtered.txt</td><td>11459099</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-70-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-70-filtered.txt</td><td>11431260</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-71-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-71-filtered.txt</td><td>11465722</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-72-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-72-filtered.txt</td><td>11495024</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-73-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-73-filtered.txt</td><td>11474806</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-74-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-74-filtered.txt</td><td>11491417</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-75-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-75-filtered.txt</td><td>11484503</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-76-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-76-filtered.txt</td><td>11458149</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-77-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-77-filtered.txt</td><td>11473636</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-78-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-78-filtered.txt</td><td>11479521</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-79-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-79-filtered.txt</td><td>11430938</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-8-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-8-filtered.txt</td><td>11455035</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-80-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-80-filtered.txt</td><td>11464432</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-81-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-81-filtered.txt</td><td>11473302</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-82-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-82-filtered.txt</td><td>11457728</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-83-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-83-filtered.txt</td><td>11510120</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-84-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-84-filtered.txt</td><td>11459989</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-85-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-85-filtered.txt</td><td>11487885</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-86-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-86-filtered.txt</td><td>11492162</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-87-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-87-filtered.txt</td><td>11487948</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-88-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-88-filtered.txt</td><td>11452445</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-89-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-89-filtered.txt</td><td>11507487</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-9-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-9-filtered.txt</td><td>11450336</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-90-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-90-filtered.txt</td><td>11525239</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-91-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-91-filtered.txt</td><td>11468711</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-92-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-92-filtered.txt</td><td>11458184</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-93-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-93-filtered.txt</td><td>11474240</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-94-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-94-filtered.txt</td><td>11471885</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-95-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-95-filtered.txt</td><td>11488721</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-96-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-96-filtered.txt</td><td>11483342</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-97-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-97-filtered.txt</td><td>11451041</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-98-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-98-filtered.txt</td><td>11464391</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-99-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-99-filtered.txt</td><td>11479936</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# get Spark Session info (RUN THIS CELL AS IS)\nspark"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3d2a3653-d5f9-442a-91a0-3e99b2fa06e3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[23]: </div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[23]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.99.251.185:44784\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.0.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>spark://10.99.251.185:7077</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ","textData":null,"removedWidgets":[],"addedWidgets":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.99.251.185:44784\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.0.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>spark://10.99.251.185:7077</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "]}}],"execution_count":0},{"cell_type":"code","source":["# start SparkContext (RUN THIS CELL AS IS)\nsc = spark.sparkContext"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8c48dbc9-202c-44f0-aeb7-073c51339cf0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# OPTIONAL\n# Spark configuration Information (RUN THIS CELL AS IS)\n# sc.getConf().getAll()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3bf741f1-1e4d-4288-ae48-65cad403bcd6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["__`REMINDER:`__ If you are running this notebook in databricks, you can monitor the progress of your jobs using the Spark UI by clicking on \"view\" in the output cell below the cell you are running"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd006c2a-69a8-484b-b92f-a756c46fb569"}}},{"cell_type":"markdown","source":["# Question 1: Spark Basics.\nIn your readings and live session demos for weeks 4 and 5 you got a crash course in working with Spark. We also talked about how Spark RDDs fit into the broader picture of distributed algorithm design. The questions below cover key points from these discussions. Feel free to answer each one very briefly.\n\n### Q1 Tasks:\n\n* __a) short response:__ What is Spark? How  does it relate to Hadoop MapReduce?\n\n* __b) short response:__ In what ways does Spark follow the principles of statelessness (a.k.a. functional programming)? List at least one way in which it allows the programmer to depart from this principle. \n\n* __c) short response:__ In the context of Spark what is a 'DAG' and how do they relate to the difference between an 'action' and a 'transformation'? Why is it useful to pay attention to the DAG that underlies your Spark implementation?\n\n* __d) short response:__ Give a specific example of when we would want to `cache()` an RDD and explain why."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8033d155-0ad5-44a9-90ec-b543566a175c"}}},{"cell_type":"markdown","source":["### Q1 Student Answers:\n> __a)__ Apache Spark is an open source project that provides high-performance, general-purpose distributed computing. It enables us to process large quantities of data, beyond what can fit on a single machine, with a high-level easy-to-use API. It allows us to write the logic of data transformations in a way that can be executed across a cluser of compute nodes. MapReduce, similar to Spark, is used for high-performance, general-purpose distributed computing based on functional programming paradigm however its design principles are quite different which makes Spark 100x faster than MapReduce, allows Spark to be more interactive (REPL) than MapReduce and performs low latency SQL queries on streaming and batch data which is difficult for MapReduce to process. Spark is next generation technology to MapReduce allowing more batch, streaming, interactive analysis of large data sets.\n\n> __b)__ Spark supports lots of design principles of functional programming however it does not support full functionality of functional programming. For example, functional programming paradigm supports higher order function which take functions as arguments. Spark has built-in map, filter, reduce functions that take other functions as arguments. Also, Spark does not modify input data (RDD) instead it generates a new data structure that represents an output of the transformation. Lastly, Spark follows lazy eveluation which is central to the functional programming paradigm. Typically functional programming does not allow for side effects which means the state of the program does not change with the input parameters. This design principle of functional programming is not preserved in Spark since Spark supports shared variables (Accumulators and Broadcast) that can hold state which departs from true functional programming paradigm.\n\n> __c)__ Evaluation of RDDs in Spark is lazy. Spark does not begin computing the partitions until an action is called. An action like (reduce, count, save etc.) triggers evaluation of partitions, which in turn trigger the scheduler, which builds a directed acyclic graph (called the DAG), based on the dependencies between RDD transformations (map, filter etc.) In other words, Spark evaluates an action by working backward to define the series of steps it has to take to take to evaluate each partition. Then, using this series of steps, called the execution plan, the scheduler computes the missing partitions for each stage until it computes the final result. It is important to pay attention to DAG especially in debugging because if there is a bug during the transformation phase it will not get uncovered until one calls an action. Once the action is called then specific transformation gets executed and at that time if there is a bug it will surface itself.\n\n> __d)__ Spark RDDs are lazily evaluated, and sometimes we may wish to use the same RDD multiple times. If we do this without caching, Spark will recompute the RDD and all of its dependencies each time we call an action on the RDD. This can be especially expensive for iterative algorithms. To avoid computing an RDD multiple times, we can ask Spark to cache the data which can be used multiple times without starting from scratch and recomputing the RDD."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"26678619-fef3-4922-8211-9bac8977c81a"}}},{"cell_type":"markdown","source":["# Question 2: Similarity Metrics\nAs mentioned in the introduction to this assignment, an intuitive way to compare the meaning of two documents is to compare the list of words they contain. Given a vocabulary $V$ (feature set) we would represent each document as a vector of `1`-s and `0`-s based on whether or not it contains each word in $V$. These \"one-hot encoded\" vector representations allow us to use math to identify similar documents. However like many NLP tasks the high-dimensionality of the feature space is a challenge... especially when we start to scale up the size and number of documents we want to compare.\n\nIn this question we'll look at a toy example of document similarity analysis. Consider these 3 'documents': \n```\ndocA\tthe flight of a bumblebee\ndocB\tthe length of a flight\ndocC\tbuzzing bumblebee flight\n```\nThese documents have a total of __7__ unique words: \n>`a, bumblebee, buzzing, flight, length, of, the`.     \n\nGiven this vocabulary, the documents' vector representations are (note that one-hot encoded entries follow the order of the vocab list above):\n\n```\ndocA\t[1,1,0,1,0,1,1]\ndocB\t[1,0,0,1,1,1,1]\ndocC\t[0,1,1,1,0,0,0]\n```  \n\n### Q2 Tasks:\n\n* __a) short response:__ The cosine similarity between two vectors is $$ \\frac{A\\cdot B}{\\|A\\|\\|B\\|} $$. Explain what the the numerator and denominator of this calculation would represent in terms of word counts in documents A and B. \n\n* __b) short response:__ Explain how the Jaccard, Overlap and Dice metrics are similar/different to the calculation for cosine similarity. When would these metrics lead to different similarity rankings for a set of documents?\n\n* __c) short response:__ Calculate the cosine similarity for each pair of documents in our toy corpus. Please use markdown and $\\LaTeX$ to show your calcuations.  \n\n* __d) short response:__ According to your calculations in `part c` which pair of documents are most similar in meaning? Does this match your expecatation from reading the documents? If not, speculate about why we might have gotten this result.\n\n* __e) short response:__ In NLP common words like '`the`', '`of`', and '`a`' increase our feature space without adding a lot of signal about _semantic meaning_. Repeat your analysis from `part c` but this time ignore these three words in your calculations [__`TIP:`__ _to 'remove' stopwords just ignore the vector entries in columns corresponding to the words you wish to disregard_]. How do your results change?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"970fb8b6-2984-4298-af00-0c672f9c73c7"}}},{"cell_type":"markdown","source":["### Q2 Student Answers:\n> __a)__ The numerator is count of words common to both docA and docB. The denominator is square root of (count of words in docA multiplied by count of words in docB)\n\n> __b)__ What is similar about these metrics is we have to calculate (a) count number of common words between the two documents (b) count number of words for each of the documnets. For a given set of documents different metrics can result into different ranking depending on how many (a) duplicates exists between the documents, (b) how much overlap exists between the two documents and (c) how big is the overall corpus compared to the relative size of the document.\n\n> __c)__ \n$$ \\frac{doc_{A}\\cdot doc_{B}}{\\|doc_{A}\\|\\|doc_{B}\\|} => 4/\\sqrt{5.5} => 0.8$$\n$$ \\frac{doc_{A}\\cdot doc_{C}}{\\|doc_{A}\\|\\|doc_{C}\\|} => 2/\\sqrt{5.3} => 0.516$$\n$$ \\frac{doc_{B}\\cdot doc_{C}}{\\|doc_{B}\\|\\|doc_{C}\\|} => 1/\\sqrt{5.3} => 0.258$$\n\n> __d)__ `docA` and `docB` are most similar because they have the most common words. It is in line with my expectation.   \n\n> __e)__ After ignoring the stop words, docA and docC are most similar because they now have the most common words between them\n$$ \\frac{doc_{A}\\cdot doc_{B}}{\\|doc_{A}\\|\\|doc_{B}\\|} => 1/\\sqrt{2.2} => 0.5$$\n$$ \\frac{doc_{A}\\cdot doc_{C}}{\\|doc_{A}\\|\\|doc_{C}\\|} => 2/\\sqrt{2.3} => 0.816$$\n$$ \\frac{doc_{B}\\cdot doc_{C}}{\\|doc_{B}\\|\\|doc_{C}\\|} => 1/\\sqrt{2.3} => 0.408$$"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"57b37b03-adc6-470d-93e6-38a001ed9d5d"}}},{"cell_type":"markdown","source":["# Question 3: Synonym Detection Strategy\n\nIn the Synonym Detection task we want to compare the meaning of words, not documents. For clarity, lets call the words whose meaning we want to compare `terms`. If only we had a 'meaning document' for each `term` then we could easily use the document similarity strategy from Question 2 to figure out which `terms` have similar meaning (i.e. are 'synonyms'). Of course in order for that to work we'd have to reasonably believe that the words in these 'meaning documents' really do reflect the meaning of the `term`. For a good analysis we'd also need these 'meaning documents' to be fairly long -- the one or two sentence dictionary definition of a term isn't going to provide enough signal to distinguish between thousands and thousands of `term` meanings.\n\nThis is where the idea of co-occurrance comes in. Just like DocSim makes the assumption that words in a document tell us about the document's meaning, we're going to assume that the set of words that 'co-occur' within a small window around our term can tell us some thing about the meaning of that `term`. Remember that we're going to make this 'co-words' list (a.k.a. 'stripe') by looking at a large body of text. This stripe is our 'meaning document' in that it reflects all the kinds of situations in which our `term` gets used in real language. So another way to phrase our assumption is: we think `terms` that get used to complete lots of the same phrases probably have related meanings. This may seem like an odd assumption but computational linguists have found that it works surprisingly well in practice. Let's look at a toy example to build your intuition for why and how.\n\nConsider the opening line of Charles Dickens' _A Tale of Two Cities_:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7b8a0e30-4b8c-41dc-84f1-2a207323d6e0"}}},{"cell_type":"code","source":["corpus = \"\"\"It was the best of times, it was the worst of times, \nit was the age of wisdom it was the age of foolishness\"\"\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d4f1915c-c052-43ba-8e4a-14cd78769b79"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["There are a total of 10 unique words in this short 'corpus':"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1114ef42-676d-40df-ad99-5b63daf5037e"}}},{"cell_type":"code","source":["words = list(set(re.findall(r'\\w+', corpus.lower())))\nprint(words)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eea6d6a6-9f0c-4f11-b5ba-74fb5f33977b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[&#39;was&#39;, &#39;age&#39;, &#39;times&#39;, &#39;foolishness&#39;, &#39;the&#39;, &#39;worst&#39;, &#39;of&#39;, &#39;wisdom&#39;, &#39;it&#39;, &#39;best&#39;]\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&#39;was&#39;, &#39;age&#39;, &#39;times&#39;, &#39;foolishness&#39;, &#39;the&#39;, &#39;worst&#39;, &#39;of&#39;, &#39;wisdom&#39;, &#39;it&#39;, &#39;best&#39;]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["But of these 10 words, 4 are so common that they probably don't tell us very much about meaning."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"43738b12-587a-4ae6-a12e-816c53159426"}}},{"cell_type":"code","source":["stopwords = [\"it\", \"the\", \"was\", \"of\"]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1922900-4f8c-4255-977d-b7831aecd638"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["So we'll ignore these 'stop words' and we're left with a 6 word vocabulary:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5e56076-98d2-45e0-98eb-a473127ecd47"}}},{"cell_type":"code","source":["vocab = sorted([w for w in words if w not in stopwords])\nprint(vocab)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b14fbe1-bf19-4ed8-af19-80bd9da43871"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[&#39;age&#39;, &#39;best&#39;, &#39;foolishness&#39;, &#39;times&#39;, &#39;wisdom&#39;, &#39;worst&#39;]\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&#39;age&#39;, &#39;best&#39;, &#39;foolishness&#39;, &#39;times&#39;, &#39;wisdom&#39;, &#39;worst&#39;]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Your goal in the tasks below is to asses, which of these six words are most related to each other in meaning -- based solely on this short two line body of text.\n\n### Q3 Tasks:\n\n* __a) short response:__ Given this six word vocabulary, how many 'pairs' of words do we want to compare? More generally for a n-word vocabulary how many pairwise comparisons are there to make? \n\n* __b) code:__ In the space provided below, create a 'stripe' for each `term` in the vocabulary. This stripe should be the list of all other vocabulary words that occur within a __5 word window__ (two words on either side) of the `term`'s position in the original text.\n\n* __c) code + short response:__ Complete the provided code to turn your stripes into a 1-hot encoded co-occurrence matrix. For our 6 word vocabulary how many entries are in this matrix? How many entries are zeros? \n\n* __d) code:__ Complete the provided code to loop over all pairs and compute their cosine similarity. Please do not modify the existing code, just add your own in the spot marked.\n\n* __e) short response:__ Which pairs of words have the highest 'similarity' scores? Are these words 'synonyms' in the traditional sense? In what sense are their meanings 'similar'? Explain how our results are contingent on the input text. What would change if we had a much larger corpus?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"86729c5f-abb7-483a-af39-f8d825f586c8"}}},{"cell_type":"markdown","source":["### Q3 Student Answers:\n> __a)__ Given 6 words we will have 15 pairwise comparisons. More generally \n$$ {N\\choose 2} $$\n\n> __c)__ We have 36 entries in 6x6 matrix. We have 28 entries that are zeros.\n\n> __e)__ We get highest similarity scores for following pairs (a) __foolishness-wisdom__ and (b) __best-worst__. They are not synonyms instead they are antonyms. However they are similar in the sense the first pair describes the human behavior and the second pair describes a superlative. Since we are using the 5 word window our results are contingent on the input text as well as the size of the window. Because we have only couple of lines of text our conclusion is based on 1 or 2 data points. If we had a large corpus then our conclusion will be based on many more data points which should result in us finding the synonyms which is in line with what linguists predict. Also, with larger corpus we will have diffrent shades of grey for cosine similarity from 1 to -1 which should yield synonyms and antonyms."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"940c4d8a-92ac-48fa-9d68-c2985b70455f"}}},{"cell_type":"code","source":["# for convenience, here are the corpus & vocab list again (RUN THIS CELL AS IS)\nprint(\"CORPUS:\")\nprint(corpus)\nprint('VOCAB:')\nprint(vocab)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0bc450dc-d852-4727-bea9-a1dd9dcb261f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">CORPUS:\nIt was the best of times, it was the worst of times, \nit was the age of wisdom it was the age of foolishness\nVOCAB:\n[&#39;age&#39;, &#39;best&#39;, &#39;foolishness&#39;, &#39;times&#39;, &#39;wisdom&#39;, &#39;worst&#39;]\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">CORPUS:\nIt was the best of times, it was the worst of times, \nit was the age of wisdom it was the age of foolishness\nVOCAB:\n[&#39;age&#39;, &#39;best&#39;, &#39;foolishness&#39;, &#39;times&#39;, &#39;wisdom&#39;, &#39;worst&#39;]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/kyleiwaniec/MIDS_CV/gh-pages/best-of-times.png\" />"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1ca0159-8070-4656-aad4-8dd3d7613c23"}}},{"cell_type":"code","source":["# part b - USE THE TEXT ABOVE TO COMPLETE EACH STRIPE\nstripes = {'age':['wisdom','foolishness'], # example\n           'best':['times'], # YOU FILL IN THE REST\n           'foolishness':['age'],\n           'times': ['best','worst'],\n           'wisdom':['age'],\n           'worst':['times']}"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1496f349-0334-4739-bcf0-7dab1c1f27ae"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part c - initializing an empty co-occurrence matrix (RUN THIS CELL AS IS)\nco_matrix = pd.DataFrame({term: [0]*len(vocab) for term in vocab}, index = vocab, dtype=int)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1ecd3a39-ef2e-40f7-b43b-2b73994dc009"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part c - FILL IN THE MISSING LINE so that this cell 1-hot encodes the co-occurrence matrix\nfor term, nbrs in stripes.items():\n    for nbr in nbrs:\n        pass\n        ############# YOUR CODE HERE #################\n        co_matrix.loc[term,nbr] = 1\n        ############# (END) YOUR CODE #################\nco_matrix"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bd660ff7-1e5e-451a-8943-4e61f5d2661b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[33]: </div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[33]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>best</th>\n      <th>foolishness</th>\n      <th>times</th>\n      <th>wisdom</th>\n      <th>worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>age</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>best</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>foolishness</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>times</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>wisdom</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>worst</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>best</th>\n      <th>foolishness</th>\n      <th>times</th>\n      <th>wisdom</th>\n      <th>worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>age</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>best</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>foolishness</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>times</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>wisdom</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>worst</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part e - FILL IN THE MISSING LINES to compute the cosine similarity between each pair of terms\nfor term1, term2 in itertools.combinations(vocab, 2):\n    # one hot-encoded vectors\n    v1 = co_matrix[term1]\n    v2 = co_matrix[term2]\n    # cosine similarity\n    ############# YOUR CODE HERE #################\n    dot_v1_v2 = np.dot(v1.values, v2.values)\n    abs_v1 = np.linalg.norm(v1.values)\n    abs_v2 = np.linalg.norm(v2.values)\n    csim = dot_v1_v2/(abs_v1*abs_v2)\n    ############# (END) YOUR CODE #################    \n    print(f\"{term1}-{term2}: {csim}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"83d58793-a0b4-4c93-9510-c2cccfca1446"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">age-best: 0.0\nage-foolishness: 0.0\nage-times: 0.0\nage-wisdom: 0.0\nage-worst: 0.0\nbest-foolishness: 0.0\nbest-times: 0.0\nbest-wisdom: 0.0\nbest-worst: 1.0\nfoolishness-times: 0.0\nfoolishness-wisdom: 1.0\nfoolishness-worst: 0.0\ntimes-wisdom: 0.0\ntimes-worst: 0.0\nwisdom-worst: 0.0\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">age-best: 0.0\nage-foolishness: 0.0\nage-times: 0.0\nage-wisdom: 0.0\nage-worst: 0.0\nbest-foolishness: 0.0\nbest-times: 0.0\nbest-wisdom: 0.0\nbest-worst: 1.0\nfoolishness-times: 0.0\nfoolishness-wisdom: 1.0\nfoolishness-worst: 0.0\ntimes-wisdom: 0.0\ntimes-worst: 0.0\nwisdom-worst: 0.0\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Question 4: Pairs and Stripes at Scale\n\nAs you read in the paper by Zadeh et al, the advantage of metrics like Cosine, Dice, Overlap and Jaccard is that they are dimension independent -- that is to say, if we implement them in a smart way the computational complexity of performing these computations is independent of the number of documents we want to compare (or in our case, the number of terms that are potential synonyms). One component of a 'smart implementation' involves thinking carefully both about how you define the \"basis vocabulary\" that forms your feature set (removing stopwords, etc). Another key idea is to use a data structure that facilitates distributed calculations. The DISCO implemetation further uses a sampling strategy, but that is beyond the scope of this assignment. \n\nIn this question we'll take a closer look at the computational complexity of the synonym detection approach we took in question 3 and then revist the document similarity example as a way to explore a more efficient approach to parallelizing this analysis.\n\n### Q4 Tasks:\n\n* __a) short response:__ In question 3 you calculated the cosine similarity of pairs of words using the vector representation of their co-occurrences in a corpus. Imagine for now that you have unlimited memory on each of your nodes and describe a sequence of map & reduce steps that would start from a raw corpus and reproduce your strategy from Q3. For each step be sure to note what information would be stored in memory on your nodes and what information would need to be shuffled over the network (a bulleted list of steps with 1-2 sentences each is sufficient to answer this question).\n\n* __b) short response:__ In the asynch videos about \"Pairs and Stripes\" you were introduced to an alternative strategy. Explain two ways that using these data structures are more efficient than 1-hot encoded vectors when it comes to distributed similarity calculations [__`HINT:`__ _Consider memory constraints, amount of information being shuffled, amount of information being transfered over the network, and level of parallelization._]\n\n* __c) read provided code:__ The code below provides a streamined implementation of Document similarity analysis in Spark. Read through this code carefully. Once you are confident you understand how it works, answer the remaining questions. [__`TIP:`__ _to see the output of each transformation try commenting out the subsequent lines and adding an early `collect()` action_.]\n\n* __d) short response:__ The second mapper function, `splitWords`, emits 'postings'. The list of all 'postings' for a word is also refered to as an 'inverted index'. In your own words, define each of these terms ('postings' and 'inverted index') based on your reading of the provided code. (*DITP by Lin and Dyer also contains a chapter on the Inverted Index although in the context of Hadoop rather than Spark*).\n\n* __e) short response:__ The third mapper, `makeCompositeKeys`, loops over the inverted index to emit 'pairs' of what? Explain what information is included in the composite key created at this stage and why it makes sense to synchronize around that information in the context of performing document similarity calculations. In addition to the information included in these new keys, what other piece of information will we need to compute Jaccard or Cosine similarity?\n\n* __f) short response:__ Out of all the Spark transformations we make in this analysis, which are 'wide' transformations and which are 'narrow' transformations. Explain."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2c18be96-3f06-4085-8b74-17f50301d1a0"}}},{"cell_type":"markdown","source":["### Q4 Student Answers:\n> __a)__ __Map/Reduce Steps__\n* > Input: Corpus;\n* > Tokenize the Corpus\n* > Ignore any token in stop word list\n* > Read Corpus and check for neighbors\n* > Emit ((token, neighbor), 1)\n* > Reduce by Key (word-pair), Sum occurance count and calculate cosine similarity\n\n> __b)__ Alternative strategy will be to use Stripes instead of word pair. Thus, during map stage for each term group together pairs into an associative array and emit associatve array. Then during reduce stage performs element wise sum of associative array. Two big advantages of stripes approach is (a) reduces the shuffle size (reduce the networking traffic) (b) better use of combiner for optimizing\n\n> __c)__ _read provided code before answering d-f_ \n\n> __d)__ __Inverted index__ Normally when we tokenize a document we get a list of words that make up the document. Instead, for a given term in the vocabulary, we want list of documents that contains the specific terms, that is called inverted index. Thus, given a term, inverted index provides access to the list of documents that contain the term. Inverted index consists of postings lists. __Postings__ A postings list is comprised of individual postings, each of which consists of a document ID and a payload information about occurrences of the term in the document. The simplest payload is nothing! The most common payload, however, is term frequency (tf), or the number of times the term occurs in the document.  \n\n> __e)__ `makeCompositeKeys`loops over the inverted index and emits pair of postings or pair of documents that have a term in common. In this example the payload consists of count of words for a document. This is important piece of information we need in the reduce phase to calculate similarity metrics. In addition to the coumnt of words for each document, we also want to know number of words that are common to a document pair. We calculate this information by adding different postings emitted by the mapper. We synchronize this information to avoid multiple passes through the data as well as avoid network traffic during shuffle phase.  \n\n> __f)__ `map`, `flatmap` are narrow transformation. They are narrow because one can run these transformation on a single partition without any dependency on other partitions. This provide us embarassingly parallel processing. `reduceByKey` is a wide transformation. This is wide because to run this transformation we require to bring-in all the other partitions."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"300b95ec-2b38-41f4-80d6-d05c59c0de1e"}}},{"cell_type":"markdown","source":["A small test file: __`sample_docs.txt`__"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"48a7fd90-a135-45ac-9732-a3f24da280b3"}}},{"cell_type":"code","source":["# RUN THIS CELL AS IS\ndbutils.fs.put(hw3_path+\"sample_docs.txt\", \n\"\"\"docA\tbright blue butterfly forget\ndocB\tbest forget bright sky\ndocC\tblue sky bright sun\ndocD\tunder butterfly sky hangs\ndocE\tforget blue butterfly\"\"\", True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1146a5c-c9b8-4c94-846e-7f6188769fe8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Wrote 144 bytes.\nOut[35]: True</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Wrote 144 bytes.\nOut[35]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# RUN THIS CELL AS IS\nprint(dbutils.fs.head(hw3_path+\"sample_docs.txt\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"85f601f2-728a-497b-97bd-d9bab59b1ab6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">docA\tbright blue butterfly forget\ndocB\tbest forget bright sky\ndocC\tblue sky bright sun\ndocD\tunder butterfly sky hangs\ndocE\tforget blue butterfly\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">docA\tbright blue butterfly forget\ndocB\tbest forget bright sky\ndocC\tblue sky bright sun\ndocD\tunder butterfly sky hangs\ndocE\tforget blue butterfly\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["__Document Similarity Analysis in Spark:__"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"13d9948e-a064-4f2d-b520-b9bab3baee1e"}}},{"cell_type":"code","source":["# load data - RUN THIS CELL AS IS\ndata = sc.textFile(hw3_path+\"sample_docs.txt\")  "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"19816f2e-748b-4056-8ca0-6311e16c9594"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# helper function - RUN THIS CELL AS IS\ndef splitWords(pair):\n    \"\"\"Mapper 2: tokenize each document and emit postings.\"\"\"\n    doc, text = pair\n    words = text.split(\" \")\n    for w in words:\n        yield (w, [(doc,len(words))])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7dec6c7a-aab5-41cc-883d-abeed7ea7a28"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# helper function - RUN THIS CELL AS IS\ndef makeCompositeKey(inverted_index):\n    \"\"\"Mapper 3: loop over postings and yield pairs.\"\"\"\n    word, postings = inverted_index\n    # taking advantage of symmetry, output only (a,b), but not (b,a)\n    for subset in itertools.combinations(sorted(postings), 2):\n        yield (str(subset), 1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e2ed02f-d2a2-40bd-9b28-58640b226842"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# helper function - RUN THIS CELL AS IS\ndef jaccard(line):\n    \"\"\"Mapper 4: compute similarity scores\"\"\"\n    (doc1, n1), (doc2, n2) = ast.literal_eval(line[0])\n    total = int(line[1])\n    jaccard = total / float(int(n1) + int(n2) - total)\n    yield doc1+\" - \"+doc2, jaccard"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b72becc7-00ce-4039-a5ba-3a09c50617fe"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["data.take(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"55491c89-5e39-461c-9ca4-aabf5efec055"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[42]: [&#39;docA\\tbright blue butterfly forget&#39;,\n &#39;docB\\tbest forget bright sky&#39;,\n &#39;docC\\tblue sky bright sun&#39;,\n &#39;docD\\tunder butterfly sky hangs&#39;,\n &#39;docE\\tforget blue butterfly&#39;]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[42]: [&#39;docA\\tbright blue butterfly forget&#39;,\n &#39;docB\\tbest forget bright sky&#39;,\n &#39;docC\\tblue sky bright sun&#39;,\n &#39;docD\\tunder butterfly sky hangs&#39;,\n &#39;docE\\tforget blue butterfly&#39;]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result = data.map(lambda line: line.split('\\t')) \\\n#             .flatMap(splitWords) \\\n#             .reduceByKey(lambda x,y : x+y) \\\n#             .flatMap(makeCompositeKey) \\\n#             .reduceByKey(lambda x,y : x+y) \\\n#             .flatMap(jaccard) \\\n#             .takeOrdered(10, key=lambda x: -x[1])\nresult.collect()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f26b4b0f-3ffe-4572-86e7-443b27df44bc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[41]: [[&#39;docA&#39;, &#39;bright blue butterfly forget&#39;],\n [&#39;docB&#39;, &#39;best forget bright sky&#39;],\n [&#39;docC&#39;, &#39;blue sky bright sun&#39;],\n [&#39;docD&#39;, &#39;under butterfly sky hangs&#39;],\n [&#39;docE&#39;, &#39;forget blue butterfly&#39;]]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[41]: [[&#39;docA&#39;, &#39;bright blue butterfly forget&#39;],\n [&#39;docB&#39;, &#39;best forget bright sky&#39;],\n [&#39;docC&#39;, &#39;blue sky bright sun&#39;],\n [&#39;docD&#39;, &#39;under butterfly sky hangs&#39;],\n [&#39;docE&#39;, &#39;forget blue butterfly&#39;]]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result = data.map(lambda line: line.split('\\t')) \\\n             .flatMap(splitWords) \\\n             .reduceByKey(lambda x,y : x+y) \\\n#             .flatMap(makeCompositeKey) \\\n#             .reduceByKey(lambda x,y : x+y) \\\n#             .flatMap(jaccard) \\\n#             .takeOrdered(10, key=lambda x: -x[1])\nresult.collect()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4ef833d1-4cea-48aa-92a0-4ccc8f426c2f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[27]: [(&#39;butterfly&#39;, [(&#39;docD&#39;, 4), (&#39;docE&#39;, 3), (&#39;docA&#39;, 4)]),\n (&#39;sky&#39;, [(&#39;docD&#39;, 4), (&#39;docB&#39;, 4), (&#39;docC&#39;, 4)]),\n (&#39;bright&#39;, [(&#39;docA&#39;, 4), (&#39;docB&#39;, 4), (&#39;docC&#39;, 4)]),\n (&#39;best&#39;, [(&#39;docB&#39;, 4)]),\n (&#39;sun&#39;, [(&#39;docC&#39;, 4)]),\n (&#39;blue&#39;, [(&#39;docA&#39;, 4), (&#39;docC&#39;, 4), (&#39;docE&#39;, 3)]),\n (&#39;forget&#39;, [(&#39;docA&#39;, 4), (&#39;docB&#39;, 4), (&#39;docE&#39;, 3)]),\n (&#39;under&#39;, [(&#39;docD&#39;, 4)]),\n (&#39;hangs&#39;, [(&#39;docD&#39;, 4)])]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[27]: [(&#39;butterfly&#39;, [(&#39;docD&#39;, 4), (&#39;docE&#39;, 3), (&#39;docA&#39;, 4)]),\n (&#39;sky&#39;, [(&#39;docD&#39;, 4), (&#39;docB&#39;, 4), (&#39;docC&#39;, 4)]),\n (&#39;bright&#39;, [(&#39;docA&#39;, 4), (&#39;docB&#39;, 4), (&#39;docC&#39;, 4)]),\n (&#39;best&#39;, [(&#39;docB&#39;, 4)]),\n (&#39;sun&#39;, [(&#39;docC&#39;, 4)]),\n (&#39;blue&#39;, [(&#39;docA&#39;, 4), (&#39;docC&#39;, 4), (&#39;docE&#39;, 3)]),\n (&#39;forget&#39;, [(&#39;docA&#39;, 4), (&#39;docB&#39;, 4), (&#39;docE&#39;, 3)]),\n (&#39;under&#39;, [(&#39;docD&#39;, 4)]),\n (&#39;hangs&#39;, [(&#39;docD&#39;, 4)])]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result = data.map(lambda line: line.split('\\t')) \\\n             .flatMap(splitWords) \\\n             .reduceByKey(lambda x,y : x+y) \\\n             .flatMap(makeCompositeKey) \\\n             .reduceByKey(lambda x,y : x+y) \\\n#             .flatMap(jaccard) \\\n#             .takeOrdered(10, key=lambda x: -x[1])\nresult.collect()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bb8a24df-3bf3-4529-821b-d4b7cab75ab8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[28]: [(&#34;((&#39;docA&#39;, 4), (&#39;docB&#39;, 4))&#34;, 2),\n (&#34;((&#39;docA&#39;, 4), (&#39;docC&#39;, 4))&#34;, 2),\n (&#34;((&#39;docB&#39;, 4), (&#39;docC&#39;, 4))&#34;, 2),\n (&#34;((&#39;docD&#39;, 4), (&#39;docE&#39;, 3))&#34;, 1),\n (&#34;((&#39;docC&#39;, 4), (&#39;docD&#39;, 4))&#34;, 1),\n (&#34;((&#39;docA&#39;, 4), (&#39;docD&#39;, 4))&#34;, 1),\n (&#34;((&#39;docA&#39;, 4), (&#39;docE&#39;, 3))&#34;, 3),\n (&#34;((&#39;docB&#39;, 4), (&#39;docD&#39;, 4))&#34;, 1),\n (&#34;((&#39;docB&#39;, 4), (&#39;docE&#39;, 3))&#34;, 1),\n (&#34;((&#39;docC&#39;, 4), (&#39;docE&#39;, 3))&#34;, 1)]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[28]: [(&#34;((&#39;docA&#39;, 4), (&#39;docB&#39;, 4))&#34;, 2),\n (&#34;((&#39;docA&#39;, 4), (&#39;docC&#39;, 4))&#34;, 2),\n (&#34;((&#39;docB&#39;, 4), (&#39;docC&#39;, 4))&#34;, 2),\n (&#34;((&#39;docD&#39;, 4), (&#39;docE&#39;, 3))&#34;, 1),\n (&#34;((&#39;docC&#39;, 4), (&#39;docD&#39;, 4))&#34;, 1),\n (&#34;((&#39;docA&#39;, 4), (&#39;docD&#39;, 4))&#34;, 1),\n (&#34;((&#39;docA&#39;, 4), (&#39;docE&#39;, 3))&#34;, 3),\n (&#34;((&#39;docB&#39;, 4), (&#39;docD&#39;, 4))&#34;, 1),\n (&#34;((&#39;docB&#39;, 4), (&#39;docE&#39;, 3))&#34;, 1),\n (&#34;((&#39;docC&#39;, 4), (&#39;docE&#39;, 3))&#34;, 1)]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result = data.map(lambda line: line.split('\\t')) \\\n             .flatMap(splitWords) \\\n             .reduceByKey(lambda x,y : x+y) \\\n             .flatMap(makeCompositeKey) \\\n             .reduceByKey(lambda x,y : x+y) \\\n             .flatMap(jaccard) \\\n#             .takeOrdered(10, key=lambda x: -x[1])\nresult.collect()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f74b7bd9-604b-4941-94b8-519c5c6363d2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[29]: [(&#39;docD - docE&#39;, 0.16666666666666666),\n (&#39;docB - docC&#39;, 0.3333333333333333),\n (&#39;docC - docD&#39;, 0.14285714285714285),\n (&#39;docA - docB&#39;, 0.3333333333333333),\n (&#39;docA - docC&#39;, 0.3333333333333333),\n (&#39;docA - docE&#39;, 0.75),\n (&#39;docC - docE&#39;, 0.16666666666666666),\n (&#39;docB - docE&#39;, 0.16666666666666666),\n (&#39;docA - docD&#39;, 0.14285714285714285),\n (&#39;docB - docD&#39;, 0.14285714285714285)]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[29]: [(&#39;docD - docE&#39;, 0.16666666666666666),\n (&#39;docB - docC&#39;, 0.3333333333333333),\n (&#39;docC - docD&#39;, 0.14285714285714285),\n (&#39;docA - docB&#39;, 0.3333333333333333),\n (&#39;docA - docC&#39;, 0.3333333333333333),\n (&#39;docA - docE&#39;, 0.75),\n (&#39;docC - docE&#39;, 0.16666666666666666),\n (&#39;docB - docE&#39;, 0.16666666666666666),\n (&#39;docA - docD&#39;, 0.14285714285714285),\n (&#39;docB - docD&#39;, 0.14285714285714285)]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Spark Job - RUN THIS CELL AS IS\nresult = data.map(lambda line: line.split('\\t')) \\\n             .flatMap(splitWords) \\\n             .reduceByKey(lambda x,y : x+y) \\\n             .flatMap(makeCompositeKey) \\\n             .reduceByKey(lambda x,y : x+y) \\\n             .flatMap(jaccard) \\\n             .takeOrdered(10, key=lambda x: -x[1])\nresult"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0f6fbace-6edc-449b-ace8-7a728dd3e4dd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[30]: [(&#39;docA - docE&#39;, 0.75),\n (&#39;docB - docC&#39;, 0.3333333333333333),\n (&#39;docA - docB&#39;, 0.3333333333333333),\n (&#39;docA - docC&#39;, 0.3333333333333333),\n (&#39;docD - docE&#39;, 0.16666666666666666),\n (&#39;docC - docE&#39;, 0.16666666666666666),\n (&#39;docB - docE&#39;, 0.16666666666666666),\n (&#39;docC - docD&#39;, 0.14285714285714285),\n (&#39;docA - docD&#39;, 0.14285714285714285),\n (&#39;docB - docD&#39;, 0.14285714285714285)]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[30]: [(&#39;docA - docE&#39;, 0.75),\n (&#39;docB - docC&#39;, 0.3333333333333333),\n (&#39;docA - docB&#39;, 0.3333333333333333),\n (&#39;docA - docC&#39;, 0.3333333333333333),\n (&#39;docD - docE&#39;, 0.16666666666666666),\n (&#39;docC - docE&#39;, 0.16666666666666666),\n (&#39;docB - docE&#39;, 0.16666666666666666),\n (&#39;docC - docD&#39;, 0.14285714285714285),\n (&#39;docA - docD&#39;, 0.14285714285714285),\n (&#39;docB - docD&#39;, 0.14285714285714285)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# About the Data\nNow that you are comfortable with similarity metrics we turn to the main task in this assignment: Synonym Detection. As you saw in Question 3 the ability of our algorithm to detect words with similar meanings is highly dependent on our input text. Specifically, we need a large enough corpus of natural language that we can expose our algorithm to a realistic range of contexts in which any given word might get used. Ideally, these 'contexts' would also provide enough signal to distinguish between words with similar semantic roles but different meaning. Finding such a corpus will be easier to accomplish for some words than others.\n\nFor the main task in this portion of the homework you will use data from Google's n-gram corpus. This data is particularly convenient for our task because Google has already done the first step for us: they windowed over a large subset of the web and extracted all 5-grams. If you are interested in learning more about this dataset the original source is: http://books.google.com/ngrams/, and a large subset is available [here from AWS](https://aws.amazon.com/datasets/google-books-ngrams/). \n\nFor this assignment we have provided a subset of the 5-grams data consisting of 191 files of approximately 10MB each. These files are available in dbfs. Please only use the provided data so that we can ensure consistent results from student to student.\n\nEach row in our dataset represents one of these 5 grams in the format:\n> `(ngram) \\t (count) \\t (pages_count) \\t (books_count)`\n\n__DISCLAIMER__: In real life, we would calculate the stripes cooccurrence data from the raw text by windowing over the raw text and not from the 5-gram preprocessed data.  Calculating pairs on this 5-gram is a little corrupt as we will be double counting cooccurences. Having said that this exercise can still pull out some similar terms."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e0a89a40-41aa-4ab2-8c1b-eae852ce344a"}}},{"cell_type":"code","source":["# RUN THIS CELL AS IS. You should see multiple google-eng-all-5gram-* files in the results. If you do not see these, please let an Instructor or TA know.\ndisplay(dbutils.fs.ls('/mnt/mids-w261/HW3/'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bd929701-f5c3-4ec9-a88e-f6949f82070a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-0-filtered.txt","googlebooks-eng-all-5gram-20090715-0-filtered.txt",11444614],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-1-filtered.txt","googlebooks-eng-all-5gram-20090715-1-filtered.txt",0],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-10-filtered.txt","googlebooks-eng-all-5gram-20090715-10-filtered.txt",11447003],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-100-filtered.txt","googlebooks-eng-all-5gram-20090715-100-filtered.txt",11484723],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-101-filtered.txt","googlebooks-eng-all-5gram-20090715-101-filtered.txt",11473190],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-102-filtered.txt","googlebooks-eng-all-5gram-20090715-102-filtered.txt",11411047],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-103-filtered.txt","googlebooks-eng-all-5gram-20090715-103-filtered.txt",11479296],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-104-filtered.txt","googlebooks-eng-all-5gram-20090715-104-filtered.txt",11426686],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-105-filtered.txt","googlebooks-eng-all-5gram-20090715-105-filtered.txt",11482267],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-106-filtered.txt","googlebooks-eng-all-5gram-20090715-106-filtered.txt",11466886],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-107-filtered.txt","googlebooks-eng-all-5gram-20090715-107-filtered.txt",11485960],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-108-filtered.txt","googlebooks-eng-all-5gram-20090715-108-filtered.txt",11463278],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-109-filtered.txt","googlebooks-eng-all-5gram-20090715-109-filtered.txt",11446599],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-11-filtered.txt","googlebooks-eng-all-5gram-20090715-11-filtered.txt",11495017],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-110-filtered.txt","googlebooks-eng-all-5gram-20090715-110-filtered.txt",11450101],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-111-filtered.txt","googlebooks-eng-all-5gram-20090715-111-filtered.txt",11456942],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-112-filtered.txt","googlebooks-eng-all-5gram-20090715-112-filtered.txt",11463851],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-113-filtered.txt","googlebooks-eng-all-5gram-20090715-113-filtered.txt",11457743],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-114-filtered.txt","googlebooks-eng-all-5gram-20090715-114-filtered.txt",11480874],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-115-filtered.txt","googlebooks-eng-all-5gram-20090715-115-filtered.txt",11504547],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-116-filtered.txt","googlebooks-eng-all-5gram-20090715-116-filtered.txt",11431759],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-117-filtered.txt","googlebooks-eng-all-5gram-20090715-117-filtered.txt",11451033],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-118-filtered.txt","googlebooks-eng-all-5gram-20090715-118-filtered.txt",11499348],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-119-filtered.txt","googlebooks-eng-all-5gram-20090715-119-filtered.txt",11461816],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-12-filtered.txt","googlebooks-eng-all-5gram-20090715-12-filtered.txt",11443168],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-120-filtered.txt","googlebooks-eng-all-5gram-20090715-120-filtered.txt",11478681],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-121-filtered.txt","googlebooks-eng-all-5gram-20090715-121-filtered.txt",11452388],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-122-filtered.txt","googlebooks-eng-all-5gram-20090715-122-filtered.txt",11461706],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-123-filtered.txt","googlebooks-eng-all-5gram-20090715-123-filtered.txt",11489973],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-124-filtered.txt","googlebooks-eng-all-5gram-20090715-124-filtered.txt",11482331],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-125-filtered.txt","googlebooks-eng-all-5gram-20090715-125-filtered.txt",11462905],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-126-filtered.txt","googlebooks-eng-all-5gram-20090715-126-filtered.txt",11467767],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-127-filtered.txt","googlebooks-eng-all-5gram-20090715-127-filtered.txt",11459598],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-128-filtered.txt","googlebooks-eng-all-5gram-20090715-128-filtered.txt",11443935],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-129-filtered.txt","googlebooks-eng-all-5gram-20090715-129-filtered.txt",11433432],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-13-filtered.txt","googlebooks-eng-all-5gram-20090715-13-filtered.txt",11485635],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-130-filtered.txt","googlebooks-eng-all-5gram-20090715-130-filtered.txt",11457212],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-131-filtered.txt","googlebooks-eng-all-5gram-20090715-131-filtered.txt",11472377],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-132-filtered.txt","googlebooks-eng-all-5gram-20090715-132-filtered.txt",11493120],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-133-filtered.txt","googlebooks-eng-all-5gram-20090715-133-filtered.txt",11441679],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-134-filtered.txt","googlebooks-eng-all-5gram-20090715-134-filtered.txt",11470516],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-135-filtered.txt","googlebooks-eng-all-5gram-20090715-135-filtered.txt",11456972],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-136-filtered.txt","googlebooks-eng-all-5gram-20090715-136-filtered.txt",11492095],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-137-filtered.txt","googlebooks-eng-all-5gram-20090715-137-filtered.txt",11446669],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-138-filtered.txt","googlebooks-eng-all-5gram-20090715-138-filtered.txt",11466514],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-139-filtered.txt","googlebooks-eng-all-5gram-20090715-139-filtered.txt",11459726],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-14-filtered.txt","googlebooks-eng-all-5gram-20090715-14-filtered.txt",11442376],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-140-filtered.txt","googlebooks-eng-all-5gram-20090715-140-filtered.txt",11460720],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-141-filtered.txt","googlebooks-eng-all-5gram-20090715-141-filtered.txt",11483474],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-142-filtered.txt","googlebooks-eng-all-5gram-20090715-142-filtered.txt",11447339],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-143-filtered.txt","googlebooks-eng-all-5gram-20090715-143-filtered.txt",11526964],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-144-filtered.txt","googlebooks-eng-all-5gram-20090715-144-filtered.txt",11435580],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-145-filtered.txt","googlebooks-eng-all-5gram-20090715-145-filtered.txt",11471874],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-146-filtered.txt","googlebooks-eng-all-5gram-20090715-146-filtered.txt",11432836],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-147-filtered.txt","googlebooks-eng-all-5gram-20090715-147-filtered.txt",11459158],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-148-filtered.txt","googlebooks-eng-all-5gram-20090715-148-filtered.txt",11454244],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-149-filtered.txt","googlebooks-eng-all-5gram-20090715-149-filtered.txt",11451707],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-15-filtered.txt","googlebooks-eng-all-5gram-20090715-15-filtered.txt",11452631],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-150-filtered.txt","googlebooks-eng-all-5gram-20090715-150-filtered.txt",11473902],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-151-filtered.txt","googlebooks-eng-all-5gram-20090715-151-filtered.txt",11469708],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-152-filtered.txt","googlebooks-eng-all-5gram-20090715-152-filtered.txt",11455532],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-153-filtered.txt","googlebooks-eng-all-5gram-20090715-153-filtered.txt",11501176],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-154-filtered.txt","googlebooks-eng-all-5gram-20090715-154-filtered.txt",11515944],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-155-filtered.txt","googlebooks-eng-all-5gram-20090715-155-filtered.txt",11464571],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-156-filtered.txt","googlebooks-eng-all-5gram-20090715-156-filtered.txt",11470657],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-157-filtered.txt","googlebooks-eng-all-5gram-20090715-157-filtered.txt",11445685],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-158-filtered.txt","googlebooks-eng-all-5gram-20090715-158-filtered.txt",11472240],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-159-filtered.txt","googlebooks-eng-all-5gram-20090715-159-filtered.txt",11476035],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-16-filtered.txt","googlebooks-eng-all-5gram-20090715-16-filtered.txt",11525458],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-160-filtered.txt","googlebooks-eng-all-5gram-20090715-160-filtered.txt",11452574],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-161-filtered.txt","googlebooks-eng-all-5gram-20090715-161-filtered.txt",11464062],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-162-filtered.txt","googlebooks-eng-all-5gram-20090715-162-filtered.txt",11486898],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-163-filtered.txt","googlebooks-eng-all-5gram-20090715-163-filtered.txt",11477376],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-164-filtered.txt","googlebooks-eng-all-5gram-20090715-164-filtered.txt",11505357],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-165-filtered.txt","googlebooks-eng-all-5gram-20090715-165-filtered.txt",11462181],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-166-filtered.txt","googlebooks-eng-all-5gram-20090715-166-filtered.txt",11466783],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-167-filtered.txt","googlebooks-eng-all-5gram-20090715-167-filtered.txt",11462354],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-168-filtered.txt","googlebooks-eng-all-5gram-20090715-168-filtered.txt",11506473],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-169-filtered.txt","googlebooks-eng-all-5gram-20090715-169-filtered.txt",11472965],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-17-filtered.txt","googlebooks-eng-all-5gram-20090715-17-filtered.txt",11509921],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-170-filtered.txt","googlebooks-eng-all-5gram-20090715-170-filtered.txt",11469219],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-171-filtered.txt","googlebooks-eng-all-5gram-20090715-171-filtered.txt",11467382],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-172-filtered.txt","googlebooks-eng-all-5gram-20090715-172-filtered.txt",11415310],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-173-filtered.txt","googlebooks-eng-all-5gram-20090715-173-filtered.txt",11457481],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-174-filtered.txt","googlebooks-eng-all-5gram-20090715-174-filtered.txt",11496657],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-175-filtered.txt","googlebooks-eng-all-5gram-20090715-175-filtered.txt",11470283],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-176-filtered.txt","googlebooks-eng-all-5gram-20090715-176-filtered.txt",11441689],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-177-filtered.txt","googlebooks-eng-all-5gram-20090715-177-filtered.txt",11484462],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-178-filtered.txt","googlebooks-eng-all-5gram-20090715-178-filtered.txt",11494587],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-179-filtered.txt","googlebooks-eng-all-5gram-20090715-179-filtered.txt",11430020],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-18-filtered.txt","googlebooks-eng-all-5gram-20090715-18-filtered.txt",11492843],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-180-filtered.txt","googlebooks-eng-all-5gram-20090715-180-filtered.txt",11464793],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-181-filtered.txt","googlebooks-eng-all-5gram-20090715-181-filtered.txt",11478471],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-182-filtered.txt","googlebooks-eng-all-5gram-20090715-182-filtered.txt",11505360],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-183-filtered.txt","googlebooks-eng-all-5gram-20090715-183-filtered.txt",11486325],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-184-filtered.txt","googlebooks-eng-all-5gram-20090715-184-filtered.txt",11452312],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-185-filtered.txt","googlebooks-eng-all-5gram-20090715-185-filtered.txt",11457259],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-186-filtered.txt","googlebooks-eng-all-5gram-20090715-186-filtered.txt",11471607],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-187-filtered.txt","googlebooks-eng-all-5gram-20090715-187-filtered.txt",11444970],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-188-filtered.txt","googlebooks-eng-all-5gram-20090715-188-filtered.txt",11456589],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-189-filtered.txt","googlebooks-eng-all-5gram-20090715-189-filtered.txt",11445694],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-19-filtered.txt","googlebooks-eng-all-5gram-20090715-19-filtered.txt",11446280],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-2-filtered.txt","googlebooks-eng-all-5gram-20090715-2-filtered.txt",11469040],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-20-filtered.txt","googlebooks-eng-all-5gram-20090715-20-filtered.txt",11483940],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-21-filtered.txt","googlebooks-eng-all-5gram-20090715-21-filtered.txt",11419380],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-22-filtered.txt","googlebooks-eng-all-5gram-20090715-22-filtered.txt",11504055],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-23-filtered.txt","googlebooks-eng-all-5gram-20090715-23-filtered.txt",11444833],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-24-filtered.txt","googlebooks-eng-all-5gram-20090715-24-filtered.txt",11470920],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-25-filtered.txt","googlebooks-eng-all-5gram-20090715-25-filtered.txt",11447510],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-26-filtered.txt","googlebooks-eng-all-5gram-20090715-26-filtered.txt",11451162],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-27-filtered.txt","googlebooks-eng-all-5gram-20090715-27-filtered.txt",11432861],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-28-filtered.txt","googlebooks-eng-all-5gram-20090715-28-filtered.txt",11473738],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-29-filtered.txt","googlebooks-eng-all-5gram-20090715-29-filtered.txt",11466285],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-3-filtered.txt","googlebooks-eng-all-5gram-20090715-3-filtered.txt",11473472],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-30-filtered.txt","googlebooks-eng-all-5gram-20090715-30-filtered.txt",11451427],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-31-filtered.txt","googlebooks-eng-all-5gram-20090715-31-filtered.txt",11445890],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-32-filtered.txt","googlebooks-eng-all-5gram-20090715-32-filtered.txt",11451034],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-33-filtered.txt","googlebooks-eng-all-5gram-20090715-33-filtered.txt",11448837],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-34-filtered.txt","googlebooks-eng-all-5gram-20090715-34-filtered.txt",11477127],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-35-filtered.txt","googlebooks-eng-all-5gram-20090715-35-filtered.txt",11482525],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-36-filtered.txt","googlebooks-eng-all-5gram-20090715-36-filtered.txt",11485001],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-37-filtered.txt","googlebooks-eng-all-5gram-20090715-37-filtered.txt",11462556],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-38-filtered.txt","googlebooks-eng-all-5gram-20090715-38-filtered.txt",11471356],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-39-filtered.txt","googlebooks-eng-all-5gram-20090715-39-filtered.txt",11463027],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-4-filtered.txt","googlebooks-eng-all-5gram-20090715-4-filtered.txt",11474462],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-40-filtered.txt","googlebooks-eng-all-5gram-20090715-40-filtered.txt",11479067],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-41-filtered.txt","googlebooks-eng-all-5gram-20090715-41-filtered.txt",11492731],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-42-filtered.txt","googlebooks-eng-all-5gram-20090715-42-filtered.txt",11444143],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-43-filtered.txt","googlebooks-eng-all-5gram-20090715-43-filtered.txt",11457891],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-44-filtered.txt","googlebooks-eng-all-5gram-20090715-44-filtered.txt",11477565],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-45-filtered.txt","googlebooks-eng-all-5gram-20090715-45-filtered.txt",11491534],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-46-filtered.txt","googlebooks-eng-all-5gram-20090715-46-filtered.txt",0],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-47-filtered.txt","googlebooks-eng-all-5gram-20090715-47-filtered.txt",11437493],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-48-filtered.txt","googlebooks-eng-all-5gram-20090715-48-filtered.txt",11486342],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-49-filtered.txt","googlebooks-eng-all-5gram-20090715-49-filtered.txt",11506157],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-5-filtered.txt","googlebooks-eng-all-5gram-20090715-5-filtered.txt",11486767],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-50-filtered.txt","googlebooks-eng-all-5gram-20090715-50-filtered.txt",11448291],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-51-filtered.txt","googlebooks-eng-all-5gram-20090715-51-filtered.txt",11466332],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-52-filtered.txt","googlebooks-eng-all-5gram-20090715-52-filtered.txt",11454748],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-53-filtered.txt","googlebooks-eng-all-5gram-20090715-53-filtered.txt",11473706],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-54-filtered.txt","googlebooks-eng-all-5gram-20090715-54-filtered.txt",11449750],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-55-filtered.txt","googlebooks-eng-all-5gram-20090715-55-filtered.txt",11440722],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-56-filtered.txt","googlebooks-eng-all-5gram-20090715-56-filtered.txt",11443428],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-57-filtered.txt","googlebooks-eng-all-5gram-20090715-57-filtered.txt",11523191],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-58-filtered.txt","googlebooks-eng-all-5gram-20090715-58-filtered.txt",11464003],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-59-filtered.txt","googlebooks-eng-all-5gram-20090715-59-filtered.txt",11450319],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-6-filtered.txt","googlebooks-eng-all-5gram-20090715-6-filtered.txt",11465378],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-60-filtered.txt","googlebooks-eng-all-5gram-20090715-60-filtered.txt",11477145],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-61-filtered.txt","googlebooks-eng-all-5gram-20090715-61-filtered.txt",11484900],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-62-filtered.txt","googlebooks-eng-all-5gram-20090715-62-filtered.txt",11461230],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-63-filtered.txt","googlebooks-eng-all-5gram-20090715-63-filtered.txt",11479759],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-64-filtered.txt","googlebooks-eng-all-5gram-20090715-64-filtered.txt",11445477],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-65-filtered.txt","googlebooks-eng-all-5gram-20090715-65-filtered.txt",11519941],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-66-filtered.txt","googlebooks-eng-all-5gram-20090715-66-filtered.txt",11455135],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-67-filtered.txt","googlebooks-eng-all-5gram-20090715-67-filtered.txt",11463820],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-68-filtered.txt","googlebooks-eng-all-5gram-20090715-68-filtered.txt",11502857],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-69-filtered.txt","googlebooks-eng-all-5gram-20090715-69-filtered.txt",11510895],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-7-filtered.txt","googlebooks-eng-all-5gram-20090715-7-filtered.txt",11459099],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-70-filtered.txt","googlebooks-eng-all-5gram-20090715-70-filtered.txt",11431260],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-71-filtered.txt","googlebooks-eng-all-5gram-20090715-71-filtered.txt",11465722],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-72-filtered.txt","googlebooks-eng-all-5gram-20090715-72-filtered.txt",11495024],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-73-filtered.txt","googlebooks-eng-all-5gram-20090715-73-filtered.txt",11474806],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-74-filtered.txt","googlebooks-eng-all-5gram-20090715-74-filtered.txt",11491417],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-75-filtered.txt","googlebooks-eng-all-5gram-20090715-75-filtered.txt",11484503],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-76-filtered.txt","googlebooks-eng-all-5gram-20090715-76-filtered.txt",11458149],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-77-filtered.txt","googlebooks-eng-all-5gram-20090715-77-filtered.txt",11473636],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-78-filtered.txt","googlebooks-eng-all-5gram-20090715-78-filtered.txt",11479521],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-79-filtered.txt","googlebooks-eng-all-5gram-20090715-79-filtered.txt",11430938],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-8-filtered.txt","googlebooks-eng-all-5gram-20090715-8-filtered.txt",11455035],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-80-filtered.txt","googlebooks-eng-all-5gram-20090715-80-filtered.txt",11464432],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-81-filtered.txt","googlebooks-eng-all-5gram-20090715-81-filtered.txt",11473302],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-82-filtered.txt","googlebooks-eng-all-5gram-20090715-82-filtered.txt",11457728],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-83-filtered.txt","googlebooks-eng-all-5gram-20090715-83-filtered.txt",11510120],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-84-filtered.txt","googlebooks-eng-all-5gram-20090715-84-filtered.txt",11459989],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-85-filtered.txt","googlebooks-eng-all-5gram-20090715-85-filtered.txt",11487885],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-86-filtered.txt","googlebooks-eng-all-5gram-20090715-86-filtered.txt",11492162],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-87-filtered.txt","googlebooks-eng-all-5gram-20090715-87-filtered.txt",11487948],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-88-filtered.txt","googlebooks-eng-all-5gram-20090715-88-filtered.txt",11452445],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-89-filtered.txt","googlebooks-eng-all-5gram-20090715-89-filtered.txt",11507487],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-9-filtered.txt","googlebooks-eng-all-5gram-20090715-9-filtered.txt",11450336],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-90-filtered.txt","googlebooks-eng-all-5gram-20090715-90-filtered.txt",11525239],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-91-filtered.txt","googlebooks-eng-all-5gram-20090715-91-filtered.txt",11468711],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-92-filtered.txt","googlebooks-eng-all-5gram-20090715-92-filtered.txt",11458184],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-93-filtered.txt","googlebooks-eng-all-5gram-20090715-93-filtered.txt",11474240],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-94-filtered.txt","googlebooks-eng-all-5gram-20090715-94-filtered.txt",11471885],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-95-filtered.txt","googlebooks-eng-all-5gram-20090715-95-filtered.txt",11488721],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-96-filtered.txt","googlebooks-eng-all-5gram-20090715-96-filtered.txt",11483342],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-97-filtered.txt","googlebooks-eng-all-5gram-20090715-97-filtered.txt",11451041],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-98-filtered.txt","googlebooks-eng-all-5gram-20090715-98-filtered.txt",11464391],["dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-99-filtered.txt","googlebooks-eng-all-5gram-20090715-99-filtered.txt",11479936]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-0-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-0-filtered.txt</td><td>11444614</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-1-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-1-filtered.txt</td><td>0</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-10-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-10-filtered.txt</td><td>11447003</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-100-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-100-filtered.txt</td><td>11484723</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-101-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-101-filtered.txt</td><td>11473190</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-102-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-102-filtered.txt</td><td>11411047</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-103-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-103-filtered.txt</td><td>11479296</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-104-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-104-filtered.txt</td><td>11426686</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-105-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-105-filtered.txt</td><td>11482267</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-106-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-106-filtered.txt</td><td>11466886</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-107-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-107-filtered.txt</td><td>11485960</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-108-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-108-filtered.txt</td><td>11463278</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-109-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-109-filtered.txt</td><td>11446599</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-11-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-11-filtered.txt</td><td>11495017</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-110-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-110-filtered.txt</td><td>11450101</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-111-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-111-filtered.txt</td><td>11456942</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-112-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-112-filtered.txt</td><td>11463851</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-113-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-113-filtered.txt</td><td>11457743</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-114-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-114-filtered.txt</td><td>11480874</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-115-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-115-filtered.txt</td><td>11504547</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-116-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-116-filtered.txt</td><td>11431759</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-117-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-117-filtered.txt</td><td>11451033</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-118-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-118-filtered.txt</td><td>11499348</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-119-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-119-filtered.txt</td><td>11461816</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-12-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-12-filtered.txt</td><td>11443168</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-120-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-120-filtered.txt</td><td>11478681</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-121-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-121-filtered.txt</td><td>11452388</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-122-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-122-filtered.txt</td><td>11461706</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-123-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-123-filtered.txt</td><td>11489973</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-124-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-124-filtered.txt</td><td>11482331</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-125-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-125-filtered.txt</td><td>11462905</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-126-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-126-filtered.txt</td><td>11467767</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-127-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-127-filtered.txt</td><td>11459598</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-128-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-128-filtered.txt</td><td>11443935</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-129-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-129-filtered.txt</td><td>11433432</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-13-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-13-filtered.txt</td><td>11485635</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-130-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-130-filtered.txt</td><td>11457212</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-131-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-131-filtered.txt</td><td>11472377</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-132-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-132-filtered.txt</td><td>11493120</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-133-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-133-filtered.txt</td><td>11441679</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-134-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-134-filtered.txt</td><td>11470516</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-135-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-135-filtered.txt</td><td>11456972</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-136-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-136-filtered.txt</td><td>11492095</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-137-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-137-filtered.txt</td><td>11446669</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-138-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-138-filtered.txt</td><td>11466514</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-139-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-139-filtered.txt</td><td>11459726</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-14-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-14-filtered.txt</td><td>11442376</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-140-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-140-filtered.txt</td><td>11460720</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-141-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-141-filtered.txt</td><td>11483474</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-142-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-142-filtered.txt</td><td>11447339</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-143-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-143-filtered.txt</td><td>11526964</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-144-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-144-filtered.txt</td><td>11435580</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-145-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-145-filtered.txt</td><td>11471874</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-146-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-146-filtered.txt</td><td>11432836</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-147-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-147-filtered.txt</td><td>11459158</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-148-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-148-filtered.txt</td><td>11454244</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-149-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-149-filtered.txt</td><td>11451707</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-15-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-15-filtered.txt</td><td>11452631</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-150-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-150-filtered.txt</td><td>11473902</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-151-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-151-filtered.txt</td><td>11469708</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-152-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-152-filtered.txt</td><td>11455532</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-153-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-153-filtered.txt</td><td>11501176</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-154-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-154-filtered.txt</td><td>11515944</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-155-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-155-filtered.txt</td><td>11464571</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-156-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-156-filtered.txt</td><td>11470657</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-157-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-157-filtered.txt</td><td>11445685</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-158-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-158-filtered.txt</td><td>11472240</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-159-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-159-filtered.txt</td><td>11476035</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-16-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-16-filtered.txt</td><td>11525458</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-160-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-160-filtered.txt</td><td>11452574</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-161-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-161-filtered.txt</td><td>11464062</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-162-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-162-filtered.txt</td><td>11486898</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-163-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-163-filtered.txt</td><td>11477376</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-164-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-164-filtered.txt</td><td>11505357</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-165-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-165-filtered.txt</td><td>11462181</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-166-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-166-filtered.txt</td><td>11466783</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-167-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-167-filtered.txt</td><td>11462354</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-168-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-168-filtered.txt</td><td>11506473</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-169-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-169-filtered.txt</td><td>11472965</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-17-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-17-filtered.txt</td><td>11509921</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-170-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-170-filtered.txt</td><td>11469219</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-171-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-171-filtered.txt</td><td>11467382</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-172-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-172-filtered.txt</td><td>11415310</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-173-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-173-filtered.txt</td><td>11457481</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-174-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-174-filtered.txt</td><td>11496657</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-175-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-175-filtered.txt</td><td>11470283</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-176-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-176-filtered.txt</td><td>11441689</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-177-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-177-filtered.txt</td><td>11484462</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-178-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-178-filtered.txt</td><td>11494587</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-179-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-179-filtered.txt</td><td>11430020</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-18-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-18-filtered.txt</td><td>11492843</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-180-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-180-filtered.txt</td><td>11464793</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-181-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-181-filtered.txt</td><td>11478471</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-182-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-182-filtered.txt</td><td>11505360</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-183-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-183-filtered.txt</td><td>11486325</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-184-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-184-filtered.txt</td><td>11452312</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-185-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-185-filtered.txt</td><td>11457259</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-186-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-186-filtered.txt</td><td>11471607</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-187-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-187-filtered.txt</td><td>11444970</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-188-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-188-filtered.txt</td><td>11456589</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-189-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-189-filtered.txt</td><td>11445694</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-19-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-19-filtered.txt</td><td>11446280</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-2-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-2-filtered.txt</td><td>11469040</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-20-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-20-filtered.txt</td><td>11483940</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-21-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-21-filtered.txt</td><td>11419380</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-22-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-22-filtered.txt</td><td>11504055</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-23-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-23-filtered.txt</td><td>11444833</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-24-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-24-filtered.txt</td><td>11470920</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-25-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-25-filtered.txt</td><td>11447510</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-26-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-26-filtered.txt</td><td>11451162</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-27-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-27-filtered.txt</td><td>11432861</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-28-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-28-filtered.txt</td><td>11473738</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-29-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-29-filtered.txt</td><td>11466285</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-3-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-3-filtered.txt</td><td>11473472</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-30-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-30-filtered.txt</td><td>11451427</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-31-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-31-filtered.txt</td><td>11445890</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-32-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-32-filtered.txt</td><td>11451034</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-33-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-33-filtered.txt</td><td>11448837</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-34-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-34-filtered.txt</td><td>11477127</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-35-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-35-filtered.txt</td><td>11482525</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-36-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-36-filtered.txt</td><td>11485001</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-37-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-37-filtered.txt</td><td>11462556</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-38-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-38-filtered.txt</td><td>11471356</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-39-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-39-filtered.txt</td><td>11463027</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-4-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-4-filtered.txt</td><td>11474462</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-40-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-40-filtered.txt</td><td>11479067</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-41-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-41-filtered.txt</td><td>11492731</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-42-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-42-filtered.txt</td><td>11444143</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-43-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-43-filtered.txt</td><td>11457891</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-44-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-44-filtered.txt</td><td>11477565</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-45-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-45-filtered.txt</td><td>11491534</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-46-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-46-filtered.txt</td><td>0</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-47-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-47-filtered.txt</td><td>11437493</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-48-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-48-filtered.txt</td><td>11486342</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-49-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-49-filtered.txt</td><td>11506157</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-5-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-5-filtered.txt</td><td>11486767</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-50-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-50-filtered.txt</td><td>11448291</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-51-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-51-filtered.txt</td><td>11466332</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-52-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-52-filtered.txt</td><td>11454748</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-53-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-53-filtered.txt</td><td>11473706</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-54-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-54-filtered.txt</td><td>11449750</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-55-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-55-filtered.txt</td><td>11440722</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-56-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-56-filtered.txt</td><td>11443428</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-57-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-57-filtered.txt</td><td>11523191</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-58-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-58-filtered.txt</td><td>11464003</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-59-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-59-filtered.txt</td><td>11450319</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-6-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-6-filtered.txt</td><td>11465378</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-60-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-60-filtered.txt</td><td>11477145</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-61-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-61-filtered.txt</td><td>11484900</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-62-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-62-filtered.txt</td><td>11461230</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-63-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-63-filtered.txt</td><td>11479759</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-64-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-64-filtered.txt</td><td>11445477</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-65-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-65-filtered.txt</td><td>11519941</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-66-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-66-filtered.txt</td><td>11455135</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-67-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-67-filtered.txt</td><td>11463820</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-68-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-68-filtered.txt</td><td>11502857</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-69-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-69-filtered.txt</td><td>11510895</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-7-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-7-filtered.txt</td><td>11459099</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-70-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-70-filtered.txt</td><td>11431260</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-71-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-71-filtered.txt</td><td>11465722</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-72-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-72-filtered.txt</td><td>11495024</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-73-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-73-filtered.txt</td><td>11474806</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-74-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-74-filtered.txt</td><td>11491417</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-75-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-75-filtered.txt</td><td>11484503</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-76-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-76-filtered.txt</td><td>11458149</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-77-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-77-filtered.txt</td><td>11473636</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-78-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-78-filtered.txt</td><td>11479521</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-79-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-79-filtered.txt</td><td>11430938</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-8-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-8-filtered.txt</td><td>11455035</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-80-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-80-filtered.txt</td><td>11464432</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-81-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-81-filtered.txt</td><td>11473302</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-82-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-82-filtered.txt</td><td>11457728</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-83-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-83-filtered.txt</td><td>11510120</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-84-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-84-filtered.txt</td><td>11459989</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-85-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-85-filtered.txt</td><td>11487885</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-86-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-86-filtered.txt</td><td>11492162</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-87-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-87-filtered.txt</td><td>11487948</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-88-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-88-filtered.txt</td><td>11452445</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-89-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-89-filtered.txt</td><td>11507487</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-9-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-9-filtered.txt</td><td>11450336</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-90-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-90-filtered.txt</td><td>11525239</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-91-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-91-filtered.txt</td><td>11468711</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-92-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-92-filtered.txt</td><td>11458184</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-93-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-93-filtered.txt</td><td>11474240</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-94-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-94-filtered.txt</td><td>11471885</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-95-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-95-filtered.txt</td><td>11488721</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-96-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-96-filtered.txt</td><td>11483342</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-97-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-97-filtered.txt</td><td>11451041</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-98-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-98-filtered.txt</td><td>11464391</td></tr><tr><td>dbfs:/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-99-filtered.txt</td><td>googlebooks-eng-all-5gram-20090715-99-filtered.txt</td><td>11479936</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# set global paths to full data folder and to the first file (which we'll use for testing)\nNGRAMS = '/mnt/mids-w261/HW3'\nF1_PATH = '/mnt/mids-w261/HW3/googlebooks-eng-all-5gram-20090715-0-filtered.txt'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bce7b7ee-3cc7-4dc0-931f-2014be636287"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["As you develop your code you should use the following file to systems test each of your solutions before running it on the Google data. (Note: these are the 5-grams extracted from our two line Dickens corpus in Question 3... you should find that your Spark job results match the calculations we did \"by hand\").\n\nTest file: __`systems_test.txt`__"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f92be2e1-9f43-488e-977f-7654c42d2d48"}}},{"cell_type":"code","source":["# RUN THIS CELL AS IS\ndbutils.fs.put(hw3_path+\"systems_test.txt\",\n\"\"\"it was the best of\t1\t1\t1\nage of wisdom it was\t1\t1\t1\nbest of times it was\t1\t1\t1\nit was the age of\t2\t1\t1\nit was the worst of\t1\t1\t1\nof times it was the\t2\t1\t1\nof wisdom it was the\t1\t1\t1\nthe age of wisdom it\t1\t1\t1\nthe best of times it\t1\t1\t1\nthe worst of times it\t1\t1\t1\ntimes it was the age\t1\t1\t1\ntimes it was the worst\t1\t1\t1\nwas the age of wisdom\t1\t1\t1\nwas the best of times\t1\t1\t1\nwas the age of foolishness\t1\t1\t1\nwas the worst of times\t1\t1\t1\nwisdom it was the age\t1\t1\t1\nworst of times it was\t1\t1\t1\"\"\",True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"232f6934-8592-4507-916e-1c6f7ac08b47"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Wrote 493 bytes.\nOut[33]: True</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Wrote 493 bytes.\nOut[33]: True</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Finally, we'll create a Spark RDD for each of these files so that they're easy to access throughout the rest of the assignment."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d1663999-0bb1-4524-87ef-18847b1fd2bb"}}},{"cell_type":"code","source":["# RUN THIS CELL AS IS Spark RDDs for each dataset\ntestRDD = sc.textFile(hw3_path+\"systems_test.txt\") \nf1RDD = sc.textFile(F1_PATH)\ndataRDD = sc.textFile(NGRAMS)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c0307e1-91a4-4153-8830-20990e25d203"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Let's take a peak at what each of these RDDs looks like:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"49cf37a8-b288-4716-aeb7-715f67d129b4"}}},{"cell_type":"code","source":["testRDD.take(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21211e25-b3b1-49b1-ad82-472934468afe"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[35]: [&#39;it was the best of\\t1\\t1\\t1&#39;,\n &#39;age of wisdom it was\\t1\\t1\\t1&#39;,\n &#39;best of times it was\\t1\\t1\\t1&#39;,\n &#39;it was the age of\\t2\\t1\\t1&#39;,\n &#39;it was the worst of\\t1\\t1\\t1&#39;,\n &#39;of times it was the\\t2\\t1\\t1&#39;,\n &#39;of wisdom it was the\\t1\\t1\\t1&#39;,\n &#39;the age of wisdom it\\t1\\t1\\t1&#39;,\n &#39;the best of times it\\t1\\t1\\t1&#39;,\n &#39;the worst of times it\\t1\\t1\\t1&#39;]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[35]: [&#39;it was the best of\\t1\\t1\\t1&#39;,\n &#39;age of wisdom it was\\t1\\t1\\t1&#39;,\n &#39;best of times it was\\t1\\t1\\t1&#39;,\n &#39;it was the age of\\t2\\t1\\t1&#39;,\n &#39;it was the worst of\\t1\\t1\\t1&#39;,\n &#39;of times it was the\\t2\\t1\\t1&#39;,\n &#39;of wisdom it was the\\t1\\t1\\t1&#39;,\n &#39;the age of wisdom it\\t1\\t1\\t1&#39;,\n &#39;the best of times it\\t1\\t1\\t1&#39;,\n &#39;the worst of times it\\t1\\t1\\t1&#39;]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["f1RDD.take(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21ea567f-c279-4551-aae9-2c091300783e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[36]: [&#39;A BILL FOR ESTABLISHING RELIGIOUS\\t59\\t59\\t54&#39;,\n &#39;A Biography of General George\\t92\\t90\\t74&#39;,\n &#39;A Case Study in Government\\t102\\t102\\t78&#39;,\n &#39;A Case Study of Female\\t447\\t447\\t327&#39;,\n &#39;A Case Study of Limited\\t55\\t55\\t43&#39;,\n &#34;A Child&#39;s Christmas in Wales\\t1099\\t1061\\t866&#34;,\n &#39;A Circumstantial Narrative of the\\t62\\t62\\t50&#39;,\n &#39;A City by the Sea\\t62\\t60\\t49&#39;,\n &#39;A Collection of Fairy Tales\\t123\\t117\\t80&#39;,\n &#39;A Collection of Forms of\\t116\\t103\\t82&#39;]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[36]: [&#39;A BILL FOR ESTABLISHING RELIGIOUS\\t59\\t59\\t54&#39;,\n &#39;A Biography of General George\\t92\\t90\\t74&#39;,\n &#39;A Case Study in Government\\t102\\t102\\t78&#39;,\n &#39;A Case Study of Female\\t447\\t447\\t327&#39;,\n &#39;A Case Study of Limited\\t55\\t55\\t43&#39;,\n &#34;A Child&#39;s Christmas in Wales\\t1099\\t1061\\t866&#34;,\n &#39;A Circumstantial Narrative of the\\t62\\t62\\t50&#39;,\n &#39;A City by the Sea\\t62\\t60\\t49&#39;,\n &#39;A Collection of Fairy Tales\\t123\\t117\\t80&#39;,\n &#39;A Collection of Forms of\\t116\\t103\\t82&#39;]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["dataRDD.take(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"57696af5-f0f5-4079-90bd-b05b5e5a3af0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[37]: [&#39;A BILL FOR ESTABLISHING RELIGIOUS\\t59\\t59\\t54&#39;,\n &#39;A Biography of General George\\t92\\t90\\t74&#39;,\n &#39;A Case Study in Government\\t102\\t102\\t78&#39;,\n &#39;A Case Study of Female\\t447\\t447\\t327&#39;,\n &#39;A Case Study of Limited\\t55\\t55\\t43&#39;,\n &#34;A Child&#39;s Christmas in Wales\\t1099\\t1061\\t866&#34;,\n &#39;A Circumstantial Narrative of the\\t62\\t62\\t50&#39;,\n &#39;A City by the Sea\\t62\\t60\\t49&#39;,\n &#39;A Collection of Fairy Tales\\t123\\t117\\t80&#39;,\n &#39;A Collection of Forms of\\t116\\t103\\t82&#39;]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[37]: [&#39;A BILL FOR ESTABLISHING RELIGIOUS\\t59\\t59\\t54&#39;,\n &#39;A Biography of General George\\t92\\t90\\t74&#39;,\n &#39;A Case Study in Government\\t102\\t102\\t78&#39;,\n &#39;A Case Study of Female\\t447\\t447\\t327&#39;,\n &#39;A Case Study of Limited\\t55\\t55\\t43&#39;,\n &#34;A Child&#39;s Christmas in Wales\\t1099\\t1061\\t866&#34;,\n &#39;A Circumstantial Narrative of the\\t62\\t62\\t50&#39;,\n &#39;A City by the Sea\\t62\\t60\\t49&#39;,\n &#39;A Collection of Fairy Tales\\t123\\t117\\t80&#39;,\n &#39;A Collection of Forms of\\t116\\t103\\t82&#39;]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Question 5: N-gram EDA part 1 (words)\n\nBefore starting our synonym-detection, let's get a sense for this data. As you saw in questions 3 and 4 the size of the vocabulary will impact the amount of computation we have to do. Write a Spark job that will accomplish the three tasks below as efficiently as possible. (No credit will be awarded for jobs that sort or subset after calling `collect()`-- use the framework to get the minimum information requested). As you develop your code, systems test each job on the provided file with Dickens ngrams, then on a single file from the Ngram dataset before running the full analysis.\n\n\n### Q5 Tasks:\n* __a) code:__ Write a Spark application to retrieve:\n  * The number of unique words that appear in the data. (i.e. size of the vocabulary) \n  * A list of the top 10 words & their counts.\n  * A list of the bottom 10 words & their counts.  \n  \n  __`NOTE  1:`__ _don't forget to lower case the ngrams before extracting words._  \n  __`NOTE  2:`__ _don't forget to take in to account the number of occurances of each ngram._  \n  __`NOTE  3:`__ _to make this code more reusable, the `EDA1` function code base uses a parameter 'n' to specify the number of top/bottom words to print (in this case we've requested 10)._\n\n\n* __b) short response:__ Given the vocab size you found in part a, how many potential synonym pairs could we form from this corpus? If each term's stripe were 1000 words long, how many individual 'postings' tuples would we need to shuffle inorder to form the inverted indices? Show and briefly explain your calculations for each part of this question. [__`HINT:`__ see your work from q4 for a review of these concepts.]\n\n* __c) short response:__ What do you notice about the most frequent words, how usefull will these top words be in synonym detection? Explain.\n\n* __d) short response:__ What do you notice/infer about the least frequent words, how reliable should we expect the detected 'synonyms' for the bottom words to be? Explain."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"78cef4c9-4f6a-45dd-a1e3-5419ea10215e"}}},{"cell_type":"markdown","source":["### Q5 Student Answers:\n\n> __b)__ Given the vocab size of 269,339 we could form $$ {269339\\choose 2} $$ synonyms pairs. If each terms's stripe were 1000 words long, we will need to shuffle $$ 269339 * {1000\\choose 2} $$ postings to form inverted index\n\n> __c)__ Most frequent words are proposition etc. that do not convery meaning. Thus, they are not useful and should be eliminated from our analysis\n\n> __d)__ Least frequent words are words which are esoteric, hardly used words. It means there is not enough context from which we can discern their meaning."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a5f44468-4b19-45cd-9fa3-a5da3949a931"}}},{"cell_type":"code","source":["# part a - write your spark job here \ndef EDA1(rdd, n):\n    total, top_n, bottom_n = None, None, None\n    ############# YOUR CODE HERE ###############\n    def splitWords(payload):\n      ngram, count, page, book = payload\n      words = ngram.lower().split(\" \")\n      for w in words:\n        yield (w, int(count))\n        \n    result = rdd.map(lambda line: line.split('\\t')) \\\n             .flatMap(splitWords) \\\n             .reduceByKey(lambda x,y : int(x)+int(y)) \\\n             .cache()\n    \n    bottom_n = result.takeOrdered(n, key=lambda x: x[1])\n    top_n = result.takeOrdered(n, key=lambda x: -x[1])\n    total = result.count()\n    ############# (END) YOUR CODE ##############\n    return total, top_n, bottom_n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1e911fc-b97d-42a5-82f1-f51a4d64f56e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part a - run the system test (RUN THIS CELL AS IS... use display cell below to see results)\nimport time\nstart = time.time()\nvocab_size, most_frequent, least_frequent = EDA1(testRDD, 10)\nprint(\"Wall time: {} seconds\".format(time.time() - start))\n# Command took 3.52 seconds -- by kylehamilton@ischool.berkeley.edu at 9/19/2020, 4:50:53 PM on kyle_hw"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3207689e-1976-4aaa-96f2-9b8f7b63dc76"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Wall time: 0.6355416774749756 seconds\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Wall time: 0.6355416774749756 seconds\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part a - display results (feel free to modify the formatting code if needed)\nprint(\"Vocabulary Size:\", vocab_size)\nprint(\" ---- Top Words ----|--- Bottom Words ----\")\nfor (w1, c1), (w2, c2) in zip(most_frequent, least_frequent):\n    print(f\"{w1:>8} {c1:>10} |{w2:>15} {c2:>3}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"44dba02b-c829-451c-8199-a97242bb039a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Vocabulary Size: 10\n ---- Top Words ----|--- Bottom Words ----\n     was         17 |    foolishness   1\n      of         17 |           best   4\n     the         17 |          worst   5\n      it         16 |         wisdom   5\n   times         10 |            age   8\n     age          8 |          times  10\n   worst          5 |             it  16\n  wisdom          5 |            was  17\n    best          4 |             of  17\nfoolishness          1 |            the  17\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Vocabulary Size: 10\n ---- Top Words ----|--- Bottom Words ----\n     was         17 |    foolishness   1\n      of         17 |           best   4\n     the         17 |          worst   5\n      it         16 |         wisdom   5\n   times         10 |            age   8\n     age          8 |          times  10\n   worst          5 |             it  16\n  wisdom          5 |            was  17\n    best          4 |             of  17\nfoolishness          1 |            the  17\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Expected output for testRDD:\n<pre>\n    Vocabulary Size: 10\n ---- Top Words ----|--- Bottom Words ----\n     was         17 |    foolishness   1\n      of         17 |           best   4\n     the         17 |          worst   5\n      it         16 |         wisdom   5\n   times         10 |            age   8\n     age          8 |          times  10\n   worst          5 |             it  16\n  wisdom          5 |            was  17\n    best          4 |             of  17\nfoolishness       1 |            the  17  \n</pre>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d5d4e5d0-7c79-44a9-add5-cdacc841e26f"}}},{"cell_type":"code","source":["# part a - run a single file, ie., a small sample (RUN THIS CELL AS IS)\nstart = time.time()\nvocab_size, most_frequent, least_frequent = EDA1(f1RDD, 10)\nprint(\"Wall time: {} seconds\".format(time.time() - start))\n# Command took 4.93 seconds -- by kylehamilton@ischool.berkeley.edu at 9/19/2020, 4:51:04 PM on kyle_hw"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5c4b2b5e-9e20-4867-88ef-a063063a3964"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Wall time: 2.2516891956329346 seconds\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Wall time: 2.2516891956329346 seconds\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part a - display results (feel free to modify the formatting code if needed)\nprint(\"Vocabulary Size:\", vocab_size)\nprint(\" ---- Top Words ----|--- Bottom Words ----\")\nfor (w1, c1), (w2, c2) in zip(most_frequent, least_frequent):\n    print(f\"{w1:>8} {c1:>10} |{w2:>15} {c2:>3}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70258e0c-2e6b-4d10-bb67-44905392afc0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Vocabulary Size: 36353\n ---- Top Words ----|--- Bottom Words ----\n     the   27691943 |    stakeholder  40\n      of   18590950 |          kenny  40\n      to   11601757 |         barnes  40\n      in    7470912 |         arnall  40\n       a    6926743 |     buonaparte  40\n     and    6150529 |       puzzling  40\n    that    4077421 |             hd  40\n      is    4074864 |        corisca  40\n      be    3720812 |       cristina  40\n     was    2492074 |         durban  40\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Vocabulary Size: 36353\n ---- Top Words ----|--- Bottom Words ----\n     the   27691943 |    stakeholder  40\n      of   18590950 |          kenny  40\n      to   11601757 |         barnes  40\n      in    7470912 |         arnall  40\n       a    6926743 |     buonaparte  40\n     and    6150529 |       puzzling  40\n    that    4077421 |             hd  40\n      is    4074864 |        corisca  40\n      be    3720812 |       cristina  40\n     was    2492074 |         durban  40\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Expected output for f1RDD\n<pre>\nVocabulary Size: 36353\n ---- Top Words ----|--- Bottom Words ----\n     the   27691943 |    stakeholder  40\n      of   18590950 |          kenny  40\n      to   11601757 |         barnes  40\n      in    7470912 |         arnall  40\n       a    6926743 |     buonaparte  40\n     and    6150529 |       puzzling  40\n    that    4077421 |             hd  40\n      is    4074864 |        corisca  40\n      be    3720812 |       cristina  40\n     was    2492074 |         durban  40\n</pre>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4ccaed56-603b-4524-8e0e-7d0c3580874e"}}},{"cell_type":"code","source":["# part a - run full analysis (RUN THIS CELL AS IS)\nstart = time.time()\nvocab_size, most_frequent, least_frequent = EDA1(dataRDD, 10)\nprint(\"Wall time: {} seconds\".format(time.time() - start))\n# Command took 1.30 minutes -- by kylehamilton@ischool.berkeley.edu at 9/19/2020, 4:51:15 PM on kyle_hw"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3bdeb14d-cdc0-4ac7-855c-742475bf53b5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Wall time: 164.18858098983765 seconds\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Wall time: 164.18858098983765 seconds\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part a - display results (feel free to modify the formatting code if needed)\nprint(\"Vocabulary Size:\", vocab_size)\nprint(\" ---- Top Words ----|--- Bottom Words ----\")\nfor (w1, c1), (w2, c2) in zip(most_frequent, least_frequent):\n    print(f\"{w1:>8} {c1:>10} |{w2:>15} {c2:>3}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"928cde61-9147-4030-a3d4-24d00a186a58"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Vocabulary Size: 269339\n ---- Top Words ----|--- Bottom Words ----\n     the 5490815394 |       parcival  40\n      of 3698583299 |   schwetzingen  40\n      to 2227866570 |      scholared  40\n      in 1421312776 |    scribbler&#39;s  40\n       a 1361123022 |      washermen  40\n     and 1149577477 |    unmurmuring  40\n    that  802921147 |         mildes  40\n      is  758328796 |          porti  40\n      be  688707130 |    viscerating  40\n      as  492170314 |     foretastes  40\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Vocabulary Size: 269339\n ---- Top Words ----|--- Bottom Words ----\n     the 5490815394 |       parcival  40\n      of 3698583299 |   schwetzingen  40\n      to 2227866570 |      scholared  40\n      in 1421312776 |    scribbler&#39;s  40\n       a 1361123022 |      washermen  40\n     and 1149577477 |    unmurmuring  40\n    that  802921147 |         mildes  40\n      is  758328796 |          porti  40\n      be  688707130 |    viscerating  40\n      as  492170314 |     foretastes  40\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Expected output for dataRDD:\n(bottom words might vary a little due to ties)\n<pre>\nVocabulary Size: 269339\n ---- Top Words ----|--- Bottom Words ----\n     the 5490815394 |   schwetzingen  40\n      of 3698583299 |           cras  40\n      to 2227866570 |       parcival  40\n      in 1421312776 |          porti  40\n       a 1361123022 |    scribbler's  40\n     and 1149577477 |      washermen  40\n    that  802921147 |    viscerating  40\n      is  758328796 |         mildes  40\n      be  688707130 |      scholared  40\n      as  492170314 |       jaworski  40\n</pre>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"76c2fab0-736a-423c-8faf-41300f211b3e"}}},{"cell_type":"markdown","source":["# Question 6: N-gram EDA part 2 (co-occurrences)\n\nThe computational complexity of synonym analysis depends not only on the number of words, but also on the number of co-ocurrences each word has. In this question you'll take a closer look at that aspect of our data. As before, please test each job on small \"systems test\" (Dickens ngrams) file and on a single file from the Ngram dataset before running the full analysis.\n\n### Q6 Tasks:\n* __a) code:__ Write a spark job that computes:\n  * the number of unique neighbors (i.e. 5-gram co-occuring words) for each word in the vocabulary. \n  * the top 10 words with the most \"neighbors\"\n  * the bottom 10 words with least \"neighbors\"\n  * a random sample of 1% of the words' neighbor counts  \n  __`NOTE:`__ for the last item, please return only the counts and not the words -- we'll go on to use these in a plotting function that expects a list of integers.\n\n\n* __b) short response:__ Use the provided code to plot a histogram of the sampled list from `a`. Comment on the distribution you observe. How will this distribution affect our synonym detection analysis?\n\n* __c) code + short response:__ Write a Spark Job to compare the top/bottom words from Q5 and from part a. Specifically, what % of the 1000 most/least neighbors words also appear in the list of 1000 most/least frequent words. [__`NOTE:`__ _technically these lists are short enough to comparing in memory on your local machine but please design your Spark job as if we were potentially comparing much larger lists._]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"25f2d346-68ce-43e9-bd56-d5c0081b5ff5"}}},{"cell_type":"markdown","source":["### Q6 Student Answers:\n\n> __b)__ Majority of words have co-occurance frequency of 1000 or less. Thus, for our analysis if we choose these words we can avoid outliers affecting our analysis.\n\n> __c)__ Of the 1000 words with most neighbors, 88.0 percent are also in the list of 1000 most frequent words. Of the 1000 words with least neighbors, 1.9 percent are also in the list of 1000 least frequent words. Thus, if we use top 1000 co-occurance words we ensure we also cover majority of frequently occuring words that describe the essence of the document as well. If we use the bottom 1000 co-occurance words, it will not be representative of this document."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c04cc4c2-1944-4fba-9111-9198ad610fc8"}}},{"cell_type":"code","source":["# part a - spark job\ndef EDA2(rdd,n):\n    top_n, bottom_n, sampled_counts = None, None, None\n    ############# YOUR CODE HERE ###############\n    def splitWords(payload):\n      ngram, count, page, book = payload\n      words = set(ngram.lower().split(\" \"))\n      for w1, w2 in itertools.permutations(words,2):\n        yield ((w1, w2),1)\n        \n    def createKeys(payload):\n      tup, count = payload\n      yield (tup[0], 1)\n  \n    result = rdd.map(lambda line: line.split('\\t')) \\\n             .flatMap(splitWords) \\\n             .reduceByKey(lambda x,y: x+y) \\\n             .flatMap(createKeys) \\\n             .reduceByKey(lambda x,y: x+y) \\\n             .cache()\n    \n    bottom_n = result.takeOrdered(n, key=lambda x: x[1])\n    top_n = result.takeOrdered(n, key=lambda x: -x[1])\n    sampled_counts = result.map(lambda x: x[1]).sample(False, 0.01, 0).collect()\n    ############# (END) YOUR CODE ##############\n    return top_n, bottom_n, sampled_counts"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7838c97a-e586-4cf5-baa3-366760797def"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part a - spark job\ndef EDA2(rdd,n):\n    top_n, bottom_n, sampled_counts = None, None, None\n    ############# YOUR CODE HERE ###############\n    def splitWords(payload):\n      ngram, count, page, book = payload\n      words = set(ngram.lower().split(\" \"))\n      for w1, w2 in sorted(itertools.permutations(words,2)):\n        yield ((w1, w2),1)\n        \n    def createKeys(payload):\n      tup, count = payload\n      yield (tup[0], 1)\n  \n    result = rdd.map(lambda line: line.split('\\t')) \\\n             .flatMap(splitWords) \\\n             .reduceByKey(lambda x,y: x+y) \\\n             .flatMap(createKeys) \\\n             .reduceByKey(lambda x,y: x+y) \\\n             .cache()\n    \n    bottom_n = result.takeOrdered(n, key=lambda x: x[1])\n    top_n = result.takeOrdered(n, key=lambda x: -x[1])\n    sampled_counts = result.map(lambda x: x[1]).sample(False, 0.01, 0).collect()\n    ############# (END) YOUR CODE ##############\n    return top_n, bottom_n, sampled_counts"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1c21b061-5d7f-4fe5-85e3-f3c960cde268"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part a - systems test (RUN THIS CELL AS IS)\nstart = time.time()\nmost_nbrs, least_nbrs, sample_counts = EDA2(testRDD, 10)\nprint(\"Wall time: {} seconds\".format(time.time() - start))\n# Command took 0.59 seconds -- by kylehamilton@ischool.berkeley.edu at 9/19/2020, 4:53:14 PM on kyle_hw"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"10610319-425c-4bdb-b1ed-198396958443"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Wall time: 0.5602645874023438 seconds\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Wall time: 0.5602645874023438 seconds\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part a - display results (feel free to modify the formatting code if needed)\nprint(\" --- Most Co-Words ---|--- Least Co-Words ----\")\nfor (w1, c1), (w2, c2) in zip(most_nbrs, least_nbrs):\n    print(f\"{w1:>12} {c1:>8} |{w2:>16} {c2:>4}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b267bf3c-48a7-41c3-9e71-c641a4fef0bd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"> --- Most Co-Words ---|--- Least Co-Words ----\n         was        9 |     foolishness    4\n          of        9 |           worst    5\n         the        9 |            best    5\n          it        8 |          wisdom    5\n         age        7 |             age    7\n       times        7 |           times    7\n       worst        5 |              it    8\n        best        5 |             was    9\n      wisdom        5 |              of    9\n foolishness        4 |             the    9\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"> --- Most Co-Words ---|--- Least Co-Words ----\n         was        9 |     foolishness    4\n          of        9 |           worst    5\n         the        9 |            best    5\n          it        8 |          wisdom    5\n         age        7 |             age    7\n       times        7 |           times    7\n       worst        5 |              it    8\n        best        5 |             was    9\n      wisdom        5 |              of    9\n foolishness        4 |             the    9\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Expected output for testRDD:\n<pre>\n --- Most Co-Words ---|--- Least Co-Words ----\n         was        9 |     foolishness    4\n          of        9 |            best    5\n         the        9 |           worst    5\n          it        8 |          wisdom    5\n         age        7 |             age    7\n       times        7 |           times    7\n        best        5 |              it    8\n       worst        5 |             was    9\n      wisdom        5 |              of    9\n foolishness        4 |             the    9\n </pre>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ffa93363-0944-48fd-ba36-2b246c290e8f"}}},{"cell_type":"code","source":["# part a - single file test (RUN THIS CELL AS IS)\nstart = time.time()\nmost_nbrs, least_nbrs, sample_counts = EDA2(f1RDD, 10)\nprint(\"Wall time: {} seconds\".format(time.time() - start))\n# Command took 6.34 seconds -- by kylehamilton@ischool.berkeley.edu at 9/19/2020, 4:53:42 PM on kyle_hw"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"341600db-a345-481b-b5b7-c351c4b722d2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Wall time: 14.577258825302124 seconds\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Wall time: 14.577258825302124 seconds\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part a - display results (feel free to modify the formatting code if needed)\nprint(\" --- Most Co-Words ---|--- Least Co-Words ----\")\nfor (w1, c1), (w2, c2) in zip(most_nbrs, least_nbrs):\n    print(f\"{w1:>12} {c1:>8} |{w2:>16} {c2:>4}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"38993181-f031-444d-94f6-1491534fd1bb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"> --- Most Co-Words ---|--- Least Co-Words ----\n         the    25548 |              vo    1\n          of    22496 |           pizza    2\n         and    16489 |      noncleaved    2\n          to    14249 |        premiers    2\n          in    13891 |        enclaves    2\n           a    13045 |   selectiveness    2\n        that     8011 |           trill    2\n          is     7947 |          dalles    2\n        with     7552 | destabilisation    2\n          by     7400 |     paleography    2\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"> --- Most Co-Words ---|--- Least Co-Words ----\n         the    25548 |              vo    1\n          of    22496 |           pizza    2\n         and    16489 |      noncleaved    2\n          to    14249 |        premiers    2\n          in    13891 |        enclaves    2\n           a    13045 |   selectiveness    2\n        that     8011 |           trill    2\n          is     7947 |          dalles    2\n        with     7552 | destabilisation    2\n          by     7400 |     paleography    2\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Expected output for f1RDD:\n<pre>\n --- Most Co-Words ---|--- Least Co-Words ----\n         the    25548 |              vo    1\n          of    22496 |      noncleaved    2\n         and    16489 |        premiers    2\n          to    14249 |        enclaves    2\n          in    13891 |   selectiveness    2\n           a    13045 |           trill    2\n        that     8011 |           pizza    2\n          is     7947 |            hoot    2\n        with     7552 |     palpitation    2\n          by     7400 |            twel    2\n</pre>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c79d212a-be05-41b5-9e56-c32387e337f2"}}},{"cell_type":"code","source":["# part a - full data (RUN THIS CELL AS IS)\nstart = time.time()\nmost_nbrs, least_nbrs, sample_counts = EDA2(dataRDD, 10)\nprint(\"Wall time: {} seconds\".format(time.time() - start))\n# Command took 4.12 minutes -- by kylehamilton@ischool.berkeley.edu at 9/19/2020, 4:54:10 PM on kyle_hw"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"674dbcd1-e2de-4abb-ae95-94d5e4f0d04e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Wall time: 1227.6849110126495 seconds\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Wall time: 1227.6849110126495 seconds\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part a - display results (feel free to modify the formatting code if needed)\nprint(\" --- Most Co-Words ---|--- Least Co-Words ----\")\nfor (w1, c1), (w2, c2) in zip(most_nbrs, least_nbrs):\n    print(f\"{w1:>12} {c1:>8} |{w2:>16} {c2:>4}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ef203e8b-c186-4bf8-9b5b-2348ecfafc89"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"> --- Most Co-Words ---|--- Least Co-Words ----\n         the   164982 |          cococo    1\n          of   155708 |            inin    1\n         and   132814 |        charuhas    1\n          in   110615 |         ooooooo    1\n          to    94358 |           iiiii    1\n           a    89197 |          iiiiii    1\n          by    67266 |             cnj    1\n        with    65127 |            choh    1\n        that    61174 |             neg    1\n          as    60652 |      cococococo    1\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"> --- Most Co-Words ---|--- Least Co-Words ----\n         the   164982 |          cococo    1\n          of   155708 |            inin    1\n         and   132814 |        charuhas    1\n          in   110615 |         ooooooo    1\n          to    94358 |           iiiii    1\n           a    89197 |          iiiiii    1\n          by    67266 |             cnj    1\n        with    65127 |            choh    1\n        that    61174 |             neg    1\n          as    60652 |      cococococo    1\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Expected output for dataRDD: \n(bottom words might vary a little due to ties)\n<pre>\n --- Most Co-Words ---|--- Least Co-Words ----\n         the   164982 |          cococo    1\n          of   155708 |            inin    1\n         and   132814 |        charuhas    1\n          in   110615 |         ooooooo    1\n          to    94358 |           iiiii    1\n           a    89197 |          iiiiii    1\n          by    67266 |             cnj    1\n        with    65127 |            choh    1\n        that    61174 |             neg    1\n          as    60652 |      cococococo    1\n</pre>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ecb001e5-2148-4490-b515-5a85ca5e4dc5"}}},{"cell_type":"markdown","source":["__`NOTE:`__ _before running the plotting code below, make sure that the variable_ `sample_counts` _points to the list generated in_ `part a`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c7455cc6-d1fd-4e9c-b466-ab0669445baf"}}},{"cell_type":"code","source":["# part b - plot histogram (RUN THIS CELL AS IS - feel free to modify format)\n\n# removing extreme upper tail for a better visual\ncounts = np.array(sample_counts)[np.array(sample_counts) < 6000]\nt = sum(np.array(sample_counts) > 6000)\nn = len(counts)\nprint(\"NOTE: we'll exclude the %s words with more than 6000 nbrs in this %s count sample.\" % (t,n))\n\n# set up figure\nfig, (ax1, ax2) = plt.subplots(1,2, figsize = (15,5))\n\n# plot regular hist\nax1.hist(counts, bins=50)\nax1.set_title('Freqency of Number of Co-Words', color='0.1')\nax1.set_facecolor('0.9')\nax1.tick_params(axis='both', colors='0.1')\nax1.grid(True)\n\n# plot log scale hist\nax2.hist(counts, bins=50)\nax2.set_title('(log)Freqency of Number of Co-Words', color='0.1')\nax2.set_facecolor('0.9')\nax2.tick_params(axis='both', colors='0.1')\nax2.grid(True)\nplt.yscale('log')\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a319f3f3-b5ed-49b7-95f1-912197da8cb5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/plots/223feaf1-a935-4262-9cf0-d8dac29d7d91.png","removedWidgets":[],"addedWidgets":{},"type":"image","arguments":{}}},"output_type":"display_data","data":{"image/png":"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"}}],"execution_count":0},{"cell_type":"code","source":["display(fig)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4d7fb990-6671-41ce-be25-d53fc2532c0a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/plots/a3bf0c4a-82f4-479f-b225-d7702ea22ff5.png","removedWidgets":[],"addedWidgets":{},"type":"image","arguments":{}}},"output_type":"display_data","data":{"image/png":"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"}}],"execution_count":0},{"cell_type":"code","source":["print(\"NOTE: we'll exclude the %s words with more than 6000 nbrs in this %s count sample.\" % (t,n))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d33d7b27-2184-48a6-94f9-cd284c846d9a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">NOTE: we&#39;ll exclude the 9 words with more than 6000 nbrs in this 2613 count sample.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">NOTE: we&#39;ll exclude the 9 words with more than 6000 nbrs in this 2613 count sample.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part c - spark job\ndef compareRankings(rdd1, rdd2):\n    percent_overlap = None\n    ############# YOUR CODE HERE ###############\n    #new1RDD = rdd1.map(lambda x: x[0])\n    #new2RDD = rdd2.map(lambda x: x[0])\n    total = rdd1.count() \n    match = rdd1.join(rdd2).count()\n    percent_overlap = 100*(match/total)\n    ############# (END) YOUR CODE ##############\n    return percent_overlap"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a4c239aa-42af-487b-bdfa-10fde44a599a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part c - get lists for comparison (RUN THIS CELL AS IS...)\n# (... then change 'testRDD' to 'f1RDD'/'dataRDD' when ready)\ntotal, topWords, bottomWords = EDA1(dataRDD, 1000)\ntopNbrs, bottomNbrs, sample_counts = EDA2(dataRDD, 1000)\ntwRDD = sc.parallelize(topWords)\nbwRDD = sc.parallelize(bottomWords)\ntnRDD = sc.parallelize(topNbrs)\nbnRDD = sc.parallelize(bottomNbrs)\nprint(twRDD.take(10))\nprint(tnRDD.take(10))\ntop_overlap = compareRankings(tnRDD, twRDD)\nbottom_overlap = compareRankings(bnRDD,bwRDD)\nprint(f\"Of the 1000 words with most neighbors, {top_overlap} percent are also in the list of 1000 most frequent words.\")\nprint(f\"Of the 1000 words with least neighbors, {bottom_overlap} percent are also in the list of 1000 least frequent words.\")\n# Command took 5.30 minutes -- by kylehamilton@ischool.berkeley.edu at 9/19/2020, 4:59:01 PM on kyle_hw"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"314b6adf-fdad-4f35-9da6-da60befa8982"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[(&#39;the&#39;, 5490815394), (&#39;of&#39;, 3698583299), (&#39;to&#39;, 2227866570), (&#39;in&#39;, 1421312776), (&#39;a&#39;, 1361123022), (&#39;and&#39;, 1149577477), (&#39;that&#39;, 802921147), (&#39;is&#39;, 758328796), (&#39;be&#39;, 688707130), (&#39;as&#39;, 492170314)]\n[(&#39;the&#39;, 164982), (&#39;of&#39;, 155708), (&#39;and&#39;, 132814), (&#39;in&#39;, 110615), (&#39;to&#39;, 94358), (&#39;a&#39;, 89197), (&#39;by&#39;, 67266), (&#39;with&#39;, 65127), (&#39;that&#39;, 61174), (&#39;as&#39;, 60652)]\nOf the 1000 words with most neighbors, 88.0 percent are also in the list of 1000 most frequent words.\nOf the 1000 words with least neighbors, 1.9 percent are also in the list of 1000 least frequent words.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[(&#39;the&#39;, 5490815394), (&#39;of&#39;, 3698583299), (&#39;to&#39;, 2227866570), (&#39;in&#39;, 1421312776), (&#39;a&#39;, 1361123022), (&#39;and&#39;, 1149577477), (&#39;that&#39;, 802921147), (&#39;is&#39;, 758328796), (&#39;be&#39;, 688707130), (&#39;as&#39;, 492170314)]\n[(&#39;the&#39;, 164982), (&#39;of&#39;, 155708), (&#39;and&#39;, 132814), (&#39;in&#39;, 110615), (&#39;to&#39;, 94358), (&#39;a&#39;, 89197), (&#39;by&#39;, 67266), (&#39;with&#39;, 65127), (&#39;that&#39;, 61174), (&#39;as&#39;, 60652)]\nOf the 1000 words with most neighbors, 88.0 percent are also in the list of 1000 most frequent words.\nOf the 1000 words with least neighbors, 1.9 percent are also in the list of 1000 least frequent words.\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Question 7: Basis Vocabulary & Stripes\n\nEvery word that appears in our data is a potential feature for our synonym detection analysis. However as we've discussed, some are likely to be more useful than others. In this question, you'll choose a judicious subset of these words to form our 'basis vocabulary' (i.e. feature set). Practically speaking, this means that when we build our stripes, we are only going to keep track of when a term co-occurs with one of these basis words. \n\n\n### Q7 Tasks:\n* __a) short response:__ Suppose we were deciding between two different basis vocabularies: the 1000 most frequent words or the 1000 least frequent words. How would this choice impact the quality of the synonyms we are able to detect? How does this choice relate to the ideas of 'overfitting' or 'underfitting' a training set?\n\n* __b) short response:__ If we had a much larger dataset, computing the full ordered list of words would be extremely expensive. If we need to none-the-less get an estimate of word frequency in order to decide on a basis vocabulary (feature set), what alternative strategy could we take?\n\n* __c) code:__ Write a spark job that does the following:\n  * tokenizes, removes stopwords and computes a word count on the ngram data\n  * subsets the top 10,000 words (these are the terms we'll consider as potential synonyms)\n  * subsets words 9,000-9,999 (this will be our 1,000 word basis vocabulary)    \n  (to put it another way - of the top 10,000 words, the bottom 1,000 form the basis vocabulary)\n  * saves the full 10K word list and the 1K basis vocabulary to file for use in `d`.  \n  \n  __NOTE:__ _to ensure consistency in results please use only the provided list of stopwords._  \n  __NOTE:__ _as always, be sure to test your code on small files as you develop it._  \n\n* __d) code:__ Write a spark job that builds co-occurrence stripes for the top 10K words in the ngram data using the basis vocabulary you developed in `part c`. This job/function, unlike others so far, should return an RDD (which we will then use in q8)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ea478ee7-9421-44c8-ae9e-f0ab34a921d7"}}},{"cell_type":"markdown","source":["### Q7 Student Answers:\n> __a)__ The quality of synonymns depend on how much context (stripe size) we have in the data for each of the term. The more context we have better the synonym detection. Thus, if we choose 1000 most frequent words our analysis shows it also has high number of co-occurances (large stripe size) which means we have lot more context to learn from and can provide better synonym analysis. If we were to choose the most frequent words we are overfitting the model with this training set. This means if we get a word that has a small stripe size (whether it is frequently occuring or not) we may not be able to identify its synonym most accurately. On the other hand if we choose 1000 least frequent words we are unable to say whether these words will have enough context (stripe size) and because of which we may underfit.\n\n> __b)__ As an alternative strategy we could take many random samples and calculate word frequency and choose most frequent words across all samples as our basis vocaulary."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cad79957-eb8f-487c-944c-4590d2f257c6"}}},{"cell_type":"code","source":["# part c - provided stopwords (RUN THIS CELL AS IS)\nSTOPWORDS =  ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', \n              'ourselves', 'you', 'your', 'yours', 'yourself', \n              'yourselves', 'he', 'him', 'his', 'himself', 'she', \n              'her', 'hers', 'herself', 'it', 'its', 'itself', \n              'they', 'them', 'their', 'theirs', 'themselves', \n              'what', 'which', 'who', 'whom', 'this', 'that', \n              'these', 'those', 'am', 'is', 'are', 'was', 'were', \n              'be', 'been', 'being', 'have', 'has', 'had', 'having', \n              'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', \n              'but', 'if', 'or', 'because', 'as', 'until', 'while', \n              'of', 'at', 'by', 'for', 'with', 'about', 'against', \n              'between', 'into', 'through', 'during', 'before', \n              'after', 'above', 'below', 'to', 'from', 'up', 'down', \n              'in', 'out', 'on', 'off', 'over', 'under', 'again', \n              'further', 'then', 'once', 'here', 'there', 'when', \n              'where', 'why', 'how', 'all', 'any', 'both', 'each', \n              'few', 'more', 'most', 'other', 'some', 'such', 'no', \n              'nor', 'not', 'only', 'own', 'same', 'so', 'than', \n              'too', 'very', 'should', 'can', 'now', 'will', 'just', \n              'would', 'could', 'may', 'must', 'one', 'much', \"it's\",\n              \"can't\", \"won't\", \"don't\", \"shouldn't\", \"hasn't\"]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de33fc39-3bba-40e0-ac50-62f393c2008b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["stopWords = sc.broadcast(set(STOPWORDS)) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b3806b7-3ca9-4e21-b76a-151bbb8716a1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part c - spark job\ndef get_vocab(rdd, n_total, n_basis):\n    vocab, basis = None, None    \n    ############# YOUR CODE HERE ###############\n    def splitWords(payload):\n      ngram, count, page, book = payload\n      words = ngram.lower().split(\" \")\n      vocab = [w for w in words if w not in stopWords.value]\n      for w in vocab:\n        yield (w, int(count))\n        \n    result = rdd.map(lambda line: line.split('\\t')) \\\n             .flatMap(splitWords) \\\n             .reduceByKey(lambda x,y : x+y) \\\n             .takeOrdered(n_total, key=lambda x: -x[1])\n    \n    vocab = sc.parallelize(result).map(lambda x: x[0]).collect()\n    basis = vocab[-n_basis:]\n    ############# (END) YOUR CODE ##############\n    return vocab, basis"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6803f51b-ceb1-4ded-83e0-0e9b1b13b5d4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part c - run your job (RUN THIS CELL AS IS)\nstart = time.time()\nVOCAB, BASIS = get_vocab(dataRDD, 10000, 1000)\nprint(\"Wall time: {} seconds\".format(time.time() - start))\n# Command took 1.08 minutes -- by kylehamilton@ischool.berkeley.edu at 9/19/2020, 5:05:32 PM on kyle_hw"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2962f5c9-7dea-4154-bcd9-d702b0e326c5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Wall time: 126.58910512924194 seconds\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Wall time: 126.58910512924194 seconds\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["dbutils.fs.put(hw3_path+\"vocabulary.txt\",str(VOCAB),True)\ndbutils.fs.put(hw3_path+\"basis.txt\",str(BASIS),True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a6544717-8ec0-4f9d-b0ad-a0089948abd7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Wrote 113523 bytes.\nWrote 11948 bytes.\nOut[60]: True</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Wrote 113523 bytes.\nWrote 11948 bytes.\nOut[60]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["def buildStripes(rdd, vocab, basis):\n    stripesRDD = None\n    ############# YOUR CODE HERE ###############\n    set_vocab = set(vocab)\n    set_basis = set(basis)    \n    def splitWords(payload):\n      ngram, count, page, book = payload\n      words = set(ngram.lower().split(\" \"))\n      set_words = set([w for w in words if w in set_vocab])\n      for w1 in set_words:\n        stripe = {*()} # set()\n        for w2 in set_words:\n          if w1 !=w2 and w2 in set_basis:\n            stripe.update([w2])\n        if len(stripe) > 0:\n          yield (w1, stripe)\n\n    stripesRDD = rdd.map(lambda line: line.lower().split('\\t')) \\\n             .flatMap(splitWords) \\\n             .reduceByKey(lambda x,y: x|y)\n    ############# (END) YOUR CODE ##############\n    return stripesRDD"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6fa32b08-6e4a-40c4-8753-21bb75b97657"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part d - run your systems test (RUN THIS CELL AS IS)\nVOCAB, BASIS = get_vocab(testRDD, 10, 10)\ntestStripesRDD = buildStripes(testRDD, VOCAB, BASIS)\nstart = time.time()\nprint(testStripesRDD.collect())\nprint(\"Wall time: {} seconds\".format(time.time() - start))\n# Command took 0.44 seconds -- by kylehamilton@ischool.berkeley.edu at 9/19/2020, 5:07:36 PM on kyle_hw\n# Expected results\n'''\n[('worst', {'times'}), ('best', {'times'}), ('foolishness', {'age'}), ('times', {'age', 'best', 'worst'}), ('age', {'wisdom', 'foolishness', 'times'}), ('wisdom', {'age'})]\n'''"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c943c23-761a-4bf7-a5b1-f551a35df5ad"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[(&#39;worst&#39;, {&#39;times&#39;}), (&#39;best&#39;, {&#39;times&#39;}), (&#39;foolishness&#39;, {&#39;age&#39;}), (&#39;age&#39;, {&#39;wisdom&#39;, &#39;foolishness&#39;, &#39;times&#39;}), (&#39;wisdom&#39;, {&#39;age&#39;}), (&#39;times&#39;, {&#39;age&#39;, &#39;best&#39;, &#39;worst&#39;})]\nWall time: 0.18566203117370605 seconds\nOut[62]: &#34;\\n[(&#39;worst&#39;, {&#39;times&#39;}), (&#39;best&#39;, {&#39;times&#39;}), (&#39;foolishness&#39;, {&#39;age&#39;}), (&#39;times&#39;, {&#39;age&#39;, &#39;best&#39;, &#39;worst&#39;}), (&#39;age&#39;, {&#39;wisdom&#39;, &#39;foolishness&#39;, &#39;times&#39;}), (&#39;wisdom&#39;, {&#39;age&#39;})]\\n&#34;</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[(&#39;worst&#39;, {&#39;times&#39;}), (&#39;best&#39;, {&#39;times&#39;}), (&#39;foolishness&#39;, {&#39;age&#39;}), (&#39;age&#39;, {&#39;wisdom&#39;, &#39;foolishness&#39;, &#39;times&#39;}), (&#39;wisdom&#39;, {&#39;age&#39;}), (&#39;times&#39;, {&#39;age&#39;, &#39;best&#39;, &#39;worst&#39;})]\nWall time: 0.18566203117370605 seconds\nOut[62]: &#34;\\n[(&#39;worst&#39;, {&#39;times&#39;}), (&#39;best&#39;, {&#39;times&#39;}), (&#39;foolishness&#39;, {&#39;age&#39;}), (&#39;times&#39;, {&#39;age&#39;, &#39;best&#39;, &#39;worst&#39;}), (&#39;age&#39;, {&#39;wisdom&#39;, &#39;foolishness&#39;, &#39;times&#39;}), (&#39;wisdom&#39;, {&#39;age&#39;})]\\n&#34;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part d - run your single file test (RUN THIS CELL AS IS)\nVOCAB, BASIS = get_vocab(f1RDD, 10000, 1000)\nf1StripesRDD = buildStripes(f1RDD, VOCAB, BASIS).cache()\nstart = time.time()\nprint(f1StripesRDD.top(5))\nprint(\"Wall time: {} seconds\".format(time.time() - start))\n# Command took 3.02 seconds -- by kylehamilton@ischool.berkeley.edu at 9/19/2020, 5:09:34 PM on kyle_hw\n# Expected results\n'''\n[('zippor', {'balak'}), ('zedong', {'mao'}), ('zeal', {'infallibility'}), ('youth', {'mould', 'constrained'}), ('younger', {'careers'})]\n'''"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f8d6c60-3e0f-4b11-bf23-5cb56ee93a6c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[(&#39;zippor&#39;, {&#39;balak&#39;}), (&#39;zedong&#39;, {&#39;mao&#39;}), (&#39;zeal&#39;, {&#39;infallibility&#39;}), (&#39;youth&#39;, {&#39;mould&#39;, &#39;constrained&#39;}), (&#39;younger&#39;, {&#39;careers&#39;})]\nWall time: 1.069044589996338 seconds\nOut[63]: &#34;\\n[(&#39;zippor&#39;, {&#39;balak&#39;}), (&#39;zedong&#39;, {&#39;mao&#39;}), (&#39;zeal&#39;, {&#39;infallibility&#39;}), (&#39;youth&#39;, {&#39;mould&#39;, &#39;constrained&#39;}), (&#39;younger&#39;, {&#39;careers&#39;})]\\n&#34;</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[(&#39;zippor&#39;, {&#39;balak&#39;}), (&#39;zedong&#39;, {&#39;mao&#39;}), (&#39;zeal&#39;, {&#39;infallibility&#39;}), (&#39;youth&#39;, {&#39;mould&#39;, &#39;constrained&#39;}), (&#39;younger&#39;, {&#39;careers&#39;})]\nWall time: 1.069044589996338 seconds\nOut[63]: &#34;\\n[(&#39;zippor&#39;, {&#39;balak&#39;}), (&#39;zedong&#39;, {&#39;mao&#39;}), (&#39;zeal&#39;, {&#39;infallibility&#39;}), (&#39;youth&#39;, {&#39;mould&#39;, &#39;constrained&#39;}), (&#39;younger&#39;, {&#39;careers&#39;})]\\n&#34;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part d - run the full analysis and take a look at a few stripes (RUN THIS CELL AS IS)\nVOCAB = ast.literal_eval(open(hw3_path_open+\"vocabulary.txt\", \"r\").read())\nBASIS = ast.literal_eval(open(hw3_path_open+\"basis.txt\", \"r\").read())\nstripesRDD = buildStripes(dataRDD, VOCAB, BASIS).cache()\n\nstart = time.time()\nfor wrd, stripe in stripesRDD.top(3):\n    print(wrd)\n    print(list(stripe))\n    print('-------')\nprint(\"Wall time: {} seconds\".format(time.time() - start))\n# Command took 55.51 seconds -- by kylehamilton@ischool.berkeley.edu at 9/19/2020, 5:11:38 PM on kyle_hw\n# Expected results:\n'''\nzur\n['den']\n-------\nzones\n['rupture', 'chalk', 'saturation', 'unification', 'inhibition', 'incentives', 'delimitation', 'shifting', 'molten', 'rings', 'privacy', 'israeli', 'allotted', 'mammals', 'variability', 'manipulation', 'hepatic', 'bridges', 'subordinated', 'earthquake', 'constituents']\n-------\nzone\n['camps', 'touches', 'provisional', 'fibrous', 'saturation', 'evacuated', 'prostate', 'korean', 'inhibition', 'regulatory', 'soils', 'delimitation', 'overlap', 'rainfall', 'molten', 'narrowing', 'costa', 'penetrated', 'nuclei', 'rebuilt', 'antigens', 'lingering', 'glowing', 'privacy', 'suez', 'stretches', 'conduction', 'parked', 'retina', 'disregard', 'perpetually', 'surrounds', 'enlarge', 'thrive', 'breaker', 'volcano', 'precipitation', 'earthquake', 'cytoplasm', 'transfers', 'circumference']\n-------\n'''"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8920b324-c667-47a3-8df1-c427a0c90b36"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">zones\n[&#39;remotest&#39;, &#39;adhesion&#39;, &#39;residential&#39;, &#39;subdivided&#39;, &#39;environments&#39;, &#39;gaza&#39;, &#39;saturation&#39;, &#39;localities&#39;, &#39;uppermost&#39;, &#39;warmer&#39;, &#39;buffer&#39;, &#39;parks&#39;]\n-------\nzone\n[&#39;sandy&#39;, &#39;tribal&#39;, &#39;narrower&#39;, &#39;fibrous&#39;, &#39;saturation&#39;, &#39;originate&#39;, &#39;auxiliary&#39;, &#39;ie&#39;, &#39;buffer&#39;, &#39;transitional&#39;, &#39;turbulent&#39;, &#39;vomiting&#39;, &#39;articular&#39;, &#39;poorly&#39;, &#39;intervening&#39;, &#39;officially&#39;, &#39;accumulate&#39;, &#39;assisting&#39;, &#39;flexor&#39;, &#39;traversed&#39;, &#39;unusually&#39;, &#39;uppermost&#39;, &#39;cartilage&#39;, &#39;inorganic&#39;, &#39;illuminated&#39;, &#39;glowing&#39;, &#39;contamination&#39;, &#39;trigger&#39;, &#39;defines&#39;, &#39;masculine&#39;, &#39;avoidance&#39;, &#39;residential&#39;, &#39;southeastern&#39;, &#39;penis&#39;, &#39;cracks&#39;, &#39;atlas&#39;, &#39;excitation&#39;, &#39;diffuse&#39;, &#39;persia&#39;, &#39;subdivided&#39;, &#39;alaska&#39;, &#39;guides&#39;, &#39;au&#39;, &#39;americas&#39;, &#39;penetrating&#39;, &#39;parked&#39;]\n-------\nzinc\n[&#39;ammonium&#39;, &#39;coating&#39;, &#39;pancreas&#39;, &#39;insoluble&#39;, &#34;alzheimer&#39;s&#34;, &#39;radioactive&#39;, &#39;diamond&#39;, &#39;metallic&#39;, &#39;weighing&#39;, &#39;dysfunction&#39;, &#39;wasting&#39;, &#39;phosphorus&#39;, &#39;transcription&#39;, &#39;dipped&#39;, &#39;hydroxide&#39;, &#39;burns&#39;, &#39;leukemia&#39;, &#39;dietary&#39;]\n-------\nWall time: 97.73701596260071 seconds\nOut[64]: &#34;\\nzur\\n[&#39;den&#39;]\\n-------\\nzones\\n[&#39;rupture&#39;, &#39;chalk&#39;, &#39;saturation&#39;, &#39;unification&#39;, &#39;inhibition&#39;, &#39;incentives&#39;, &#39;delimitation&#39;, &#39;shifting&#39;, &#39;molten&#39;, &#39;rings&#39;, &#39;privacy&#39;, &#39;israeli&#39;, &#39;allotted&#39;, &#39;mammals&#39;, &#39;variability&#39;, &#39;manipulation&#39;, &#39;hepatic&#39;, &#39;bridges&#39;, &#39;subordinated&#39;, &#39;earthquake&#39;, &#39;constituents&#39;]\\n-------\\nzone\\n[&#39;camps&#39;, &#39;touches&#39;, &#39;provisional&#39;, &#39;fibrous&#39;, &#39;saturation&#39;, &#39;evacuated&#39;, &#39;prostate&#39;, &#39;korean&#39;, &#39;inhibition&#39;, &#39;regulatory&#39;, &#39;soils&#39;, &#39;delimitation&#39;, &#39;overlap&#39;, &#39;rainfall&#39;, &#39;molten&#39;, &#39;narrowing&#39;, &#39;costa&#39;, &#39;penetrated&#39;, &#39;nuclei&#39;, &#39;rebuilt&#39;, &#39;antigens&#39;, &#39;lingering&#39;, &#39;glowing&#39;, &#39;privacy&#39;, &#39;suez&#39;, &#39;stretches&#39;, &#39;conduction&#39;, &#39;parked&#39;, &#39;retina&#39;, &#39;disregard&#39;, &#39;perpetually&#39;, &#39;surrounds&#39;, &#39;enlarge&#39;, &#39;thrive&#39;, &#39;breaker&#39;, &#39;volcano&#39;, &#39;precipitation&#39;, &#39;earthquake&#39;, &#39;cytoplasm&#39;, &#39;transfers&#39;, &#39;circumference&#39;]\\n-------\\n&#34;</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">zones\n[&#39;remotest&#39;, &#39;adhesion&#39;, &#39;residential&#39;, &#39;subdivided&#39;, &#39;environments&#39;, &#39;gaza&#39;, &#39;saturation&#39;, &#39;localities&#39;, &#39;uppermost&#39;, &#39;warmer&#39;, &#39;buffer&#39;, &#39;parks&#39;]\n-------\nzone\n[&#39;sandy&#39;, &#39;tribal&#39;, &#39;narrower&#39;, &#39;fibrous&#39;, &#39;saturation&#39;, &#39;originate&#39;, &#39;auxiliary&#39;, &#39;ie&#39;, &#39;buffer&#39;, &#39;transitional&#39;, &#39;turbulent&#39;, &#39;vomiting&#39;, &#39;articular&#39;, &#39;poorly&#39;, &#39;intervening&#39;, &#39;officially&#39;, &#39;accumulate&#39;, &#39;assisting&#39;, &#39;flexor&#39;, &#39;traversed&#39;, &#39;unusually&#39;, &#39;uppermost&#39;, &#39;cartilage&#39;, &#39;inorganic&#39;, &#39;illuminated&#39;, &#39;glowing&#39;, &#39;contamination&#39;, &#39;trigger&#39;, &#39;defines&#39;, &#39;masculine&#39;, &#39;avoidance&#39;, &#39;residential&#39;, &#39;southeastern&#39;, &#39;penis&#39;, &#39;cracks&#39;, &#39;atlas&#39;, &#39;excitation&#39;, &#39;diffuse&#39;, &#39;persia&#39;, &#39;subdivided&#39;, &#39;alaska&#39;, &#39;guides&#39;, &#39;au&#39;, &#39;americas&#39;, &#39;penetrating&#39;, &#39;parked&#39;]\n-------\nzinc\n[&#39;ammonium&#39;, &#39;coating&#39;, &#39;pancreas&#39;, &#39;insoluble&#39;, &#34;alzheimer&#39;s&#34;, &#39;radioactive&#39;, &#39;diamond&#39;, &#39;metallic&#39;, &#39;weighing&#39;, &#39;dysfunction&#39;, &#39;wasting&#39;, &#39;phosphorus&#39;, &#39;transcription&#39;, &#39;dipped&#39;, &#39;hydroxide&#39;, &#39;burns&#39;, &#39;leukemia&#39;, &#39;dietary&#39;]\n-------\nWall time: 97.73701596260071 seconds\nOut[64]: &#34;\\nzur\\n[&#39;den&#39;]\\n-------\\nzones\\n[&#39;rupture&#39;, &#39;chalk&#39;, &#39;saturation&#39;, &#39;unification&#39;, &#39;inhibition&#39;, &#39;incentives&#39;, &#39;delimitation&#39;, &#39;shifting&#39;, &#39;molten&#39;, &#39;rings&#39;, &#39;privacy&#39;, &#39;israeli&#39;, &#39;allotted&#39;, &#39;mammals&#39;, &#39;variability&#39;, &#39;manipulation&#39;, &#39;hepatic&#39;, &#39;bridges&#39;, &#39;subordinated&#39;, &#39;earthquake&#39;, &#39;constituents&#39;]\\n-------\\nzone\\n[&#39;camps&#39;, &#39;touches&#39;, &#39;provisional&#39;, &#39;fibrous&#39;, &#39;saturation&#39;, &#39;evacuated&#39;, &#39;prostate&#39;, &#39;korean&#39;, &#39;inhibition&#39;, &#39;regulatory&#39;, &#39;soils&#39;, &#39;delimitation&#39;, &#39;overlap&#39;, &#39;rainfall&#39;, &#39;molten&#39;, &#39;narrowing&#39;, &#39;costa&#39;, &#39;penetrated&#39;, &#39;nuclei&#39;, &#39;rebuilt&#39;, &#39;antigens&#39;, &#39;lingering&#39;, &#39;glowing&#39;, &#39;privacy&#39;, &#39;suez&#39;, &#39;stretches&#39;, &#39;conduction&#39;, &#39;parked&#39;, &#39;retina&#39;, &#39;disregard&#39;, &#39;perpetually&#39;, &#39;surrounds&#39;, &#39;enlarge&#39;, &#39;thrive&#39;, &#39;breaker&#39;, &#39;volcano&#39;, &#39;precipitation&#39;, &#39;earthquake&#39;, &#39;cytoplasm&#39;, &#39;transfers&#39;, &#39;circumference&#39;]\\n-------\\n&#34;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# print maximum number of stripes in stripesRDD\nmax(stripesRDD.mapValues(lambda x: len(x)).map(lambda x: x[1]).collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5f9808aa-4c83-4895-bb4d-ef3d9ebc05d4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[82]: 894</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[82]: 894</div>"]}}],"execution_count":0},{"cell_type":"code","source":["stripesRDD.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"92d37905-9064-40db-b94a-b083b9985328"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[83]: 9993</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[83]: 9993</div>"]}}],"execution_count":0},{"cell_type":"code","source":["len(set(BASIS))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"40df560f-841c-47d0-9c87-b506cea5f135"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[84]: 1000</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[84]: 1000</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part d - save your full stripes to file for ease of retrival later... (OPTIONAL)\n#stripesRDD.saveAsTextFile(hw3_path+'stripes')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6cdd0bd2-f210-4b65-b4dd-fa6ca459a1a0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Question 8: Synonym Detection\n\nWe're now ready to perform the main synonym detection analysis. In the tasks below you will compute cosine, jaccard, dice and overlap similarity measurements for each pair of words in our vocabulary and then sort your results to find the most similar pairs of words in this dataset. __`IMPORTANT:`__ When you get to the sorting step please __sort on cosine similarity__ only, so that we can ensure consistent results from student to student. \n\nRemember to test each step of your work with the small files before running your code on the full dataset. This is a computationally intense task: well designed code can be the difference between a 20min job and a 2hr job. __`NOTE:`__ _as you are designing your code you may want to review questions 3 and 4 where we modeled some of the key pieces of this analysis._\n\n### Q8 Tasks:\n* __a) short response:__ In question 7 you wrote a function that would create word stripes for each `term` in our vocabulary. These word stripes are essentially an 'embedded representation' of the `term`'s meaning. What is the 'feature space' for this representation? (i.e. what are the features of our 1-hot encoded vectors?). What is the maximum length of a stripe?\n\n* __b) short response:__ Remember that we are going to treat these stripes as 'documents' and perform similarity analysis on them. The first step is to emit postings which then get collected to form an 'inverted index.' How many rows will there be in our inverted index? Explain.\n\n* __c) short response:__ In the demo from question 2, we were able to compute the cosine similarity directly from the stripes (we did this using their vector form, but could have used the list instead). So why do we need the inverted index? (__`HINT:`__ _see your answer to Q4a & Q4b_)\n\n* __d) code:__ Write a spark job that does the following:\n  * loops over the stripes from Q7 and emits postings for the `term` (_remember stripe = document_)\n  * aggregates the postings to create an inverted index\n  * loops over all pairs of `term`s that appear in the same inverted index and emits co-occurrence counts\n  * aggregates co-occurrences\n  * uses the counts (along with the accompanying information) to compute the cosine, jacard, dice and overlap similarity metrics for each pair of words in the vocabulary \n  * retrieve the top 20 and bottom 20 most/least similar pairs of words\n  * also returned the cached sorted RDD for use in the next question  \n  __`NOTE 1`:__ _Don't forget to include the stripe length when you are creating the postings & co-occurrence pairs. A composite key is the way to go here._  \n  __`NOTE 2`:__ _Please make sure that your final results are sorted according to cosine similarity otherwise your results may not match the expected result & you will be marked wrong._\n  \n* __e) code:__ Comment on the quality of the \"synonyms\" your analysis comes up with. Do you notice anything odd about these pairs of words? Discuss at least one idea for how you might go about improving on the analysis."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7fc28c2-4b48-4560-b096-063c02d45233"}}},{"cell_type":"markdown","source":["### Q8 Student Answers:\n> __a)__ The feature space is the BASIS. Thus, the theoritical maximum limit for size of stripe will be size of the BASIS. In this example BASIS consits of 1000 words. Thus the maximum size for any stripe will be 1000. In our case the maximum stripe size is 894\n\n> __b)__ There will be 1000 rows in our inverted index.For each term in the BASIS we will have the total number of words in the document as well as co-occurance words.\n\n> __c)__ We need the inverted index for 1 primary reason to avoid sparse matrix representation - (a)If we were to use vector calculaus we will have to represent the entire dataset as a sparse matrix which can require huge memory space to store the vocabulary and basis as well as during vector computation. This is unlike breaking the pieces into chuncks and running job in a parallel processing\n\n> __e)__ It is difficult to discern the meaning of the word just by sorting the data using cosine similarity. Instead I will sort against the key like 'first' and look at all the pairs with \"firts-\" and do a secondary sort by cosine. This will allow me to see the progression of first with all the words which will then allow me to discern the meaning better."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1e7a0055-a96c-4f45-a67a-253584870c22"}}},{"cell_type":"code","source":["# helper function for pretty printing (RUN THIS CELL AS IS)\ndef displayOutput(lines):\n    template = \"{:25}|{:6}, {:7}, {:7}, {:5}\"\n    print(template.format(\"Pair\", \"Cosine\", \"Jaccard\", \"Overlap\", \"Dice\"))\n    for pair, scores in lines:\n        scores = [round(s,4) for s in scores]\n        print(template.format(pair, *scores))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"84f7332b-0eeb-4450-a0df-02169b82f46c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["__`TIP:`__ Feel free to define helper functions within the main function to help you organize your code. Readability is important! Eg:\n```\ndef similarityAnlysis(stripesRDD):\n    \"\"\"main docstring\"\"\"\n    \n    simScoresRDD, top_n, bottom_n = None, None, None\n    \n    ############ YOUR CODE HERE ###########\n    def helper1():\n        \"\"\"helper docstring\"\"\"\n        return x\n        \n    def helper2():\n        \"\"\"helper docstring\"\"\"\n        return x\n        \n    # main spark job starts here\n    \n        ...etc\n    ############ (END) YOUR CODE ###########\n    return simScoresRDD, top_n, bottom_n\n```"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"365e2b68-edcc-4510-ab54-487334b3cca7"}}},{"cell_type":"code","source":["# part d - write your spark job in the space provided\nimport math\ndef similarityAnalysis(stripesRDD, n):\n    \"\"\"\n    This function defines a Spark DAG to compute cosine, jaccard, \n    overlap and dice scores for each pair of words in the stripes\n    provided. \n    \n    Output: an RDD, a list of top n, a list of bottom n\n    \"\"\"\n    simScoresRDD, top_n, bottom_n = None, None, None    \n    ############### YOUR CODE HERE ################\n    def splitWords(pair):\n      \"\"\"Mapper 2: tokenize each document and emit postings.\"\"\"\n      doc, words = pair\n      for w in words:\n        yield (w, [(doc,len(words))])\n        \n    def makeCompositeKey(inverted_index):\n      \"\"\"Mapper 3: loop over postings and yield pairs.\"\"\"\n      word, postings = inverted_index\n      # taking advantage of symmetry, output only (a,b), but not (b,a)\n      for subset in itertools.combinations(sorted(postings), 2):\n        yield (str(subset), 1)\n    \n    def simMetrics(line):\n      \"\"\"Mapper 4: compute similarity scores\"\"\"\n      (doc1, n1), (doc2, n2) = ast.literal_eval(line[0])\n      total = int(line[1])\n      minof = min(int(n1), int(n2))\n      cosine = total / math.sqrt(float(int(n1)*int(n2)))\n      jaccard = total / float(int(n1) + int(n2) - total)\n      overlap = total / float(minof)\n      dice = (2*jaccard) / (1+jaccard)\n      yield ((doc1+\" - \"+doc2), (cosine, jaccard, overlap, dice))\n\n    simScoresRDD = stripesRDD.flatMap(splitWords) \\\n             .reduceByKey(lambda x,y : x+y) \\\n             .flatMap(makeCompositeKey) \\\n             .reduceByKey(lambda x,y : x+y) \\\n             .flatMap(simMetrics) \\\n             .cache()\n    \n    top_n = simScoresRDD.takeOrdered(n, key=lambda x: -x[1][0])\n    bottom_n = simScoresRDD.takeOrdered(n, key=lambda x: x[1][0])\n    ############### (END) YOUR CODE ##############\n    return simScoresRDD, top_n, bottom_n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cd08c236-34ef-4534-b026-79e932dc9804"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part d - run the system test (RUN THIS CELL AS IS... use display cell below to see results)\nstart = time.time()\ntestResult, top_n, bottom_n = similarityAnalysis(testStripesRDD, 10)\nprint(\"Wall time: {} seconds\".format(time.time() - start))\n# Command took 0.40 seconds -- by kylehamilton@ischool.berkeley.edu at 9/19/2020, 5:15:03 PM on kyle_hw"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ee7f709d-6d04-4a0a-97a9-4e5928962cbb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Wall time: 0.38147640228271484 seconds\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Wall time: 0.38147640228271484 seconds\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["displayOutput(top_n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"31fae703-c9d5-471b-ac71-454ecb81e894"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Pair                     |Cosine, Jaccard, Overlap, Dice \nbest - worst             |   1.0,     1.0,     1.0,   1.0\nfoolishness - wisdom     |   1.0,     1.0,     1.0,   1.0\ntimes - wisdom           |0.5774,  0.3333,     1.0,   0.5\nage - best               |0.5774,  0.3333,     1.0,   0.5\nage - worst              |0.5774,  0.3333,     1.0,   0.5\nfoolishness - times      |0.5774,  0.3333,     1.0,   0.5\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Pair                     |Cosine, Jaccard, Overlap, Dice \nbest - worst             |   1.0,     1.0,     1.0,   1.0\nfoolishness - wisdom     |   1.0,     1.0,     1.0,   1.0\ntimes - wisdom           |0.5774,  0.3333,     1.0,   0.5\nage - best               |0.5774,  0.3333,     1.0,   0.5\nage - worst              |0.5774,  0.3333,     1.0,   0.5\nfoolishness - times      |0.5774,  0.3333,     1.0,   0.5\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["displayOutput(bottom_n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7f30b48e-d36b-400a-9eef-e6ec89516abc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Pair                     |Cosine, Jaccard, Overlap, Dice \ntimes - wisdom           |0.5774,  0.3333,     1.0,   0.5\nage - best               |0.5774,  0.3333,     1.0,   0.5\nage - worst              |0.5774,  0.3333,     1.0,   0.5\nfoolishness - times      |0.5774,  0.3333,     1.0,   0.5\nbest - worst             |   1.0,     1.0,     1.0,   1.0\nfoolishness - wisdom     |   1.0,     1.0,     1.0,   1.0\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Pair                     |Cosine, Jaccard, Overlap, Dice \ntimes - wisdom           |0.5774,  0.3333,     1.0,   0.5\nage - best               |0.5774,  0.3333,     1.0,   0.5\nage - worst              |0.5774,  0.3333,     1.0,   0.5\nfoolishness - times      |0.5774,  0.3333,     1.0,   0.5\nbest - worst             |   1.0,     1.0,     1.0,   1.0\nfoolishness - wisdom     |   1.0,     1.0,     1.0,   1.0\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part d - run the system test (RUN THIS CELL AS IS... use display cell below to see results)\nstart = time.time()\nf1Result, top_n, bottom_n = similarityAnalysis(f1StripesRDD, 10)\nprint(\"Wall time: {} seconds\".format(time.time() - start))\n# Command took 1.11 seconds -- by kylehamilton@ischool.berkeley.edu at 9/19/2020, 5:15:34 PM on kyle_hw"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"616aa13e-c50e-49cb-8beb-c764c659c2af"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Wall time: 0.7741522789001465 seconds\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Wall time: 0.7741522789001465 seconds\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["displayOutput(top_n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"405412b2-d4df-4a04-b7cd-fc5573749b4d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Pair                     |Cosine, Jaccard, Overlap, Dice \ncontemplated - prize     |   1.0,     1.0,     1.0,   1.0\nconceived - generality   |   1.0,     1.0,     1.0,   1.0\nconceived - reality      |   1.0,     1.0,     1.0,   1.0\ngenerality - simplicity  |   1.0,     1.0,     1.0,   1.0\nreality - simplicity     |   1.0,     1.0,     1.0,   1.0\nexpect - rigid           |   1.0,     1.0,     1.0,   1.0\nfacts - rigid            |   1.0,     1.0,     1.0,   1.0\nantibody - excess        |   1.0,     1.0,     1.0,   1.0\necological - excess      |   1.0,     1.0,     1.0,   1.0\necological - stable      |   1.0,     1.0,     1.0,   1.0\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Pair                     |Cosine, Jaccard, Overlap, Dice \ncontemplated - prize     |   1.0,     1.0,     1.0,   1.0\nconceived - generality   |   1.0,     1.0,     1.0,   1.0\nconceived - reality      |   1.0,     1.0,     1.0,   1.0\ngenerality - simplicity  |   1.0,     1.0,     1.0,   1.0\nreality - simplicity     |   1.0,     1.0,     1.0,   1.0\nexpect - rigid           |   1.0,     1.0,     1.0,   1.0\nfacts - rigid            |   1.0,     1.0,     1.0,   1.0\nantibody - excess        |   1.0,     1.0,     1.0,   1.0\necological - excess      |   1.0,     1.0,     1.0,   1.0\necological - stable      |   1.0,     1.0,     1.0,   1.0\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["displayOutput(bottom_n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"019f6d1b-33ea-4630-a6fc-f3700a70280f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Pair                     |Cosine, Jaccard, Overlap, Dice \npart - time              |0.0294,  0.0149,  0.0303, 0.0294\ntime - two               |0.0309,  0.0156,  0.0333, 0.0308\ntime - upon              |0.0314,  0.0159,  0.0345, 0.0312\nmade - time              |0.0325,  0.0164,   0.037, 0.0323\nfirst - time             |0.0338,  0.0169,    0.04, 0.0333\nmade - two               |0.0351,  0.0179,   0.037, 0.0351\nnew - time               |0.0352,  0.0175,  0.0435, 0.0345\npart - us                |0.0355,  0.0179,  0.0417, 0.0351\nlittle - part            |0.0355,  0.0179,  0.0417, 0.0351\nmade - upon              |0.0357,  0.0182,   0.037, 0.0357\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Pair                     |Cosine, Jaccard, Overlap, Dice \npart - time              |0.0294,  0.0149,  0.0303, 0.0294\ntime - two               |0.0309,  0.0156,  0.0333, 0.0308\ntime - upon              |0.0314,  0.0159,  0.0345, 0.0312\nmade - time              |0.0325,  0.0164,   0.037, 0.0323\nfirst - time             |0.0338,  0.0169,    0.04, 0.0333\nmade - two               |0.0351,  0.0179,   0.037, 0.0351\nnew - time               |0.0352,  0.0175,  0.0435, 0.0345\npart - us                |0.0355,  0.0179,  0.0417, 0.0351\nlittle - part            |0.0355,  0.0179,  0.0417, 0.0351\nmade - upon              |0.0357,  0.0182,   0.037, 0.0357\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# part d - run the system test (RUN THIS CELL AS IS... use display cell below to see results)\nstart = time.time()\nresult, top_n, bottom_n = similarityAnalysis(stripesRDD, 20)\nprint(\"Wall time: {} seconds\".format(time.time() - start))\n# Command took 4.66 minutes -- by kylehamilton@ischool.berkeley.edu at 9/19/2020, 5:16:00 PM on kyle_hw"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca9c4459-8859-46ad-b869-6f3f2ba869f5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Wall time: 433.5727686882019 seconds\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Wall time: 433.5727686882019 seconds\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["displayOutput(top_n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ced75e26-e305-4029-8673-4afeac4d0e95"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Pair                     |Cosine, Jaccard, Overlap, Dice \nfirst - time             |  0.89,  0.8012,  0.9149, 0.8897\ntime - well              |0.8895,   0.801,   0.892, 0.8895\ngreat - time             | 0.875,  0.7757,   0.925, 0.8737\npart - well              | 0.874,  0.7755,  0.9018, 0.8735\nfirst - well             |0.8717,  0.7722,  0.8936, 0.8715\npart - time              |0.8715,  0.7715,  0.9018, 0.871\ntime - upon              |0.8668,   0.763,  0.9152, 0.8656\nmade - time              | 0.866,  0.7619,  0.9109, 0.8649\nmade - well              |0.8601,  0.7531,  0.9022, 0.8592\ntime - way               |0.8587,  0.7487,  0.9259, 0.8563\ngreat - well             |0.8526,  0.7412,  0.8988, 0.8514\ntime - two               |0.8517,  0.7389,  0.9094, 0.8498\nfirst - great            |0.8497,  0.7381,  0.8738, 0.8493\nfirst - part             |0.8471,  0.7348,  0.8527, 0.8471\ngreat - upon             |0.8464,  0.7338,  0.8475, 0.8464\nupon - well              |0.8444,   0.729,   0.889, 0.8433\nnew - time               |0.8426,   0.724,  0.9133, 0.8399\nfirst - two              |0.8411,  0.7249,  0.8737, 0.8405\nway - well               |0.8357,  0.7146,  0.8986, 0.8335\ntime - us                |0.8357,  0.7105,  0.9318, 0.8308\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Pair                     |Cosine, Jaccard, Overlap, Dice \nfirst - time             |  0.89,  0.8012,  0.9149, 0.8897\ntime - well              |0.8895,   0.801,   0.892, 0.8895\ngreat - time             | 0.875,  0.7757,   0.925, 0.8737\npart - well              | 0.874,  0.7755,  0.9018, 0.8735\nfirst - well             |0.8717,  0.7722,  0.8936, 0.8715\npart - time              |0.8715,  0.7715,  0.9018, 0.871\ntime - upon              |0.8668,   0.763,  0.9152, 0.8656\nmade - time              | 0.866,  0.7619,  0.9109, 0.8649\nmade - well              |0.8601,  0.7531,  0.9022, 0.8592\ntime - way               |0.8587,  0.7487,  0.9259, 0.8563\ngreat - well             |0.8526,  0.7412,  0.8988, 0.8514\ntime - two               |0.8517,  0.7389,  0.9094, 0.8498\nfirst - great            |0.8497,  0.7381,  0.8738, 0.8493\nfirst - part             |0.8471,  0.7348,  0.8527, 0.8471\ngreat - upon             |0.8464,  0.7338,  0.8475, 0.8464\nupon - well              |0.8444,   0.729,   0.889, 0.8433\nnew - time               |0.8426,   0.724,  0.9133, 0.8399\nfirst - two              |0.8411,  0.7249,  0.8737, 0.8405\nway - well               |0.8357,  0.7146,  0.8986, 0.8335\ntime - us                |0.8357,  0.7105,  0.9318, 0.8308\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["displayOutput(bottom_n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"444d4bf5-f357-4848-a719-fb4e436e5475"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Pair                     |Cosine, Jaccard, Overlap, Dice \nregion - write           |0.0067,  0.0032,  0.0085, 0.0065\nrelation - snow          |0.0067,  0.0026,  0.0141, 0.0052\ncardiac - took           |0.0074,  0.0023,  0.0217, 0.0045\never - tumor             |0.0076,   0.002,  0.0263, 0.004\ncame - tumor             |0.0076,   0.002,  0.0263, 0.004\nlet - therapy            |0.0076,   0.003,  0.0161, 0.0059\nrelated - stay           |0.0078,  0.0036,  0.0116, 0.0072\nfactors - hear           |0.0078,  0.0039,  0.0094, 0.0077\nimplications - round     |0.0078,  0.0033,  0.0145, 0.0066\ncame - proteins          |0.0079,   0.002,  0.0286, 0.0041\npopulation - window      |0.0079,  0.0039,    0.01, 0.0077\nlove - proportional      | 0.008,  0.0029,  0.0185, 0.0058\ngot - multiple           | 0.008,  0.0034,  0.0149, 0.0067\nchanges - fort           |0.0081,  0.0032,  0.0161, 0.0065\nlayer - wife             |0.0081,  0.0038,  0.0119, 0.0075\nfive - sympathy          |0.0081,  0.0034,  0.0149, 0.0068\narrival - essential      |0.0081,   0.004,  0.0093, 0.008\ndesert - function        |0.0081,  0.0031,  0.0175, 0.0062\nfundamental - stood      |0.0081,  0.0038,  0.0115, 0.0077\npatients - plain         |0.0081,   0.004,  0.0103, 0.0079\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Pair                     |Cosine, Jaccard, Overlap, Dice \nregion - write           |0.0067,  0.0032,  0.0085, 0.0065\nrelation - snow          |0.0067,  0.0026,  0.0141, 0.0052\ncardiac - took           |0.0074,  0.0023,  0.0217, 0.0045\never - tumor             |0.0076,   0.002,  0.0263, 0.004\ncame - tumor             |0.0076,   0.002,  0.0263, 0.004\nlet - therapy            |0.0076,   0.003,  0.0161, 0.0059\nrelated - stay           |0.0078,  0.0036,  0.0116, 0.0072\nfactors - hear           |0.0078,  0.0039,  0.0094, 0.0077\nimplications - round     |0.0078,  0.0033,  0.0145, 0.0066\ncame - proteins          |0.0079,   0.002,  0.0286, 0.0041\npopulation - window      |0.0079,  0.0039,    0.01, 0.0077\nlove - proportional      | 0.008,  0.0029,  0.0185, 0.0058\ngot - multiple           | 0.008,  0.0034,  0.0149, 0.0067\nchanges - fort           |0.0081,  0.0032,  0.0161, 0.0065\nlayer - wife             |0.0081,  0.0038,  0.0119, 0.0075\nfive - sympathy          |0.0081,  0.0034,  0.0149, 0.0068\narrival - essential      |0.0081,   0.004,  0.0093, 0.008\ndesert - function        |0.0081,  0.0031,  0.0175, 0.0062\nfundamental - stood      |0.0081,  0.0038,  0.0115, 0.0077\npatients - plain         |0.0081,   0.004,  0.0103, 0.0079\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e8118afa-f3db-4b02-851e-0b08d70e4e14"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[97]: 28757658</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[97]: 28757658</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["__Expected output f1RDD:__  \n<table>\n<th>MOST SIMILAR:</th>\n<th>LEAST SIMILAR:</th>\n<tr><td><pre>\nPair                     |Cosine, Jaccard, Overlap, Dice \ncommentary - lady        |   1.0,     1.0,     1.0,   1.0\ncommentary - toes        |   1.0,     1.0,     1.0,   1.0\ncommentary - reply       |   1.0,     1.0,     1.0,   1.0\ncurious - tone           |   1.0,     1.0,     1.0,   1.0\ncurious - lady           |   1.0,     1.0,     1.0,   1.0\ncurious - owe            |   1.0,     1.0,     1.0,   1.0\nlady - tone              |   1.0,     1.0,     1.0,   1.0\nreply - tone             |   1.0,     1.0,     1.0,   1.0\nlady - toes              |   1.0,     1.0,     1.0,   1.0\nlady - reply             |   1.0,     1.0,     1.0,   1.0\n</pre></td>\n<td><pre>\n\nPair                     |Cosine, Jaccard, Overlap, Dice \npart - time              |0.0294,  0.0149,  0.0303, 0.0294\ntime - upon              |0.0314,  0.0159,  0.0345, 0.0312\ntime - two               |0.0314,  0.0159,  0.0345, 0.0312\nmade - time              |0.0325,  0.0164,   0.037, 0.0323\nfirst - time             |0.0338,  0.0169,    0.04, 0.0333\nnew - time               |0.0352,  0.0175,  0.0435, 0.0345\npart - us                |0.0355,  0.0179,  0.0417, 0.0351\nlittle - part            |0.0355,  0.0179,  0.0417, 0.0351\nmade - two               |0.0357,  0.0182,   0.037, 0.0357\nmade - upon              |0.0357,  0.0182,   0.037, 0.0357\n</pre></td></tr>\n</table>\n\n__Expected output dataRDD:__  \n<table>\n<th>Most Similar</th>\n<th>Least Similar</th>\n<tr><td><pre>\nPair           |Cosine, Jaccard, Overlap, Dice \ncain - ceres             |   1.0,     1.0,     1.0,   1.0\ngyration - oscillation   |   1.0,     1.0,     1.0,   1.0\nprosecutor - reconstructed|   1.0,     1.0,     1.0,   1.0\ncondolence - zur         |   1.0,     1.0,     1.0,   1.0\nsociedad - verde         |   1.0,     1.0,     1.0,   1.0\nhong - kong              |0.8906,  0.7931,     1.0, 0.8846\ncava - vena              |0.8819,  0.7778,     1.0, 0.875\nfirst - time             |0.8715,  0.7703,  0.9199, 0.8703\ntime - well              |0.8639,  0.7599,    0.89, 0.8636\ngreat - time             |0.8563,  0.7453,   0.921, 0.8541\ntime - way               |0.8525,  0.7396,  0.9169, 0.8503\npart - time              | 0.846,  0.7308,  0.8989, 0.8445\nnova - scotia            |0.8452,  0.7143,     1.0, 0.8333\ngreat - upon             |0.8448,  0.7312,  0.8488, 0.8447\ntime - upon              |0.8447,  0.7283,  0.9042, 0.8428\nnew - time               |0.8428,  0.7239,  0.9164, 0.8398\npart - well              |0.8406,  0.7244,   0.867, 0.8402\nstates - united          |0.8383,  0.7214,  0.8541, 0.8382\nmade - time              |0.8371,  0.7155,  0.9096, 0.8342\nfirst - new              |0.8287,   0.707,  0.8538, 0.8284\n</pre></td>\n<td><pre>\nPair                  |Cosine, Jaccard, Overlap, Dice \ncity - renal             |0.0075,  0.0025,    0.02, 0.005\ndifferentiation - house  |0.0084,  0.0023,  0.0286, 0.0045\neffectiveness - got      |0.0085,  0.0034,  0.0167, 0.0068\nconditions - pulled      |0.0085,  0.0036,  0.0156, 0.0072\nlegislative - story      |0.0086,  0.0034,  0.0179, 0.0067\nduty - located           |0.0086,   0.004,   0.013, 0.0079\ngroup - listening        |0.0087,   0.003,  0.0217, 0.006\nresulting - thou         |0.0087,  0.0041,  0.0122, 0.0082\ncompletely - library     |0.0087,  0.0043,  0.0106, 0.0086\nmembrane - service       |0.0088,  0.0033,  0.0192, 0.0066\nconcentrations - never   |0.0088,   0.002,  0.0357, 0.004\nhighly - st              |0.0088,  0.0044,  0.0099, 0.0087\nassociated - kitchen     |0.0088,  0.0035,  0.0175, 0.007\ncalcium - government     |0.0088,  0.0024,  0.0294, 0.0049\ncomplex - sat            |0.0088,  0.0044,  0.0095, 0.0088\nagricultural - immediately|0.0089,  0.0039,  0.0152, 0.0077\nst - tendency            |0.0089,  0.0044,  0.0099, 0.0088\nbosom - theory           |0.0089,  0.0036,  0.0175, 0.0072\nmembers - wet            |0.0089,  0.0032,  0.0213, 0.0063\nvalues - window          |0.0089,  0.0045,  0.0099, 0.0089\n</pre></td></tr>\n</table>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"608ebf19-75e4-4874-9f12-90d0d502981b"}}},{"cell_type":"markdown","source":["### Congratulations, you have completed HW3! Please refer to the readme for submission instructions.\n\nIf you would like to provide feedback regarding this homework, please use the survey at: https://docs.google.com/forms/d/e/1FAIpQLSce9feiQeSkdP43A0ZYui1tMGIBfLfzb0rmgToQeZD9bXXX8Q/viewform"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"480f9f95-b5b4-4643-8752-81c0f7fb3581"}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bea01b40-4fd0-4e04-beac-a1b847d14608"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"hw3_Workbook","dashboards":[],"language":"python","widgets":{},"notebookOrigID":1991844521692319}},"nbformat":4,"nbformat_minor":0}
